{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Policy Gradients (DDPG and REINFORCE)\n",
    "\n",
    "Name: Chuqiao Song\n",
    "\n",
    "ID: A53239614"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "This exercise requires you to solve various continous control problems in OpenAI-Gym.  \n",
    "\n",
    "DDPG is policy gradient actor critic method for continous control which is off policy. It tackles the curse of dimensionality / loss of performance faced when discretizing a continous action domain. DDPG uses similiar \"tricks\" as DQN to improve the stability of training, including a replay buffer and target networks.\n",
    "\n",
    "Furthermore, you will implement REINFORCE for discrete and continous environments, and as a bonus compare the sample efficiency and performance with DQN and DDPG.\n",
    "\n",
    "\n",
    "### DDPG paper: https://arxiv.org/pdf/1509.02971.pdf\n",
    "\n",
    "### Environments:\n",
    "\n",
    "#### InvertedPendulum-v2 environment:\n",
    "<img src=\"inverted_pendulum.png\" width=\"300\">\n",
    "\n",
    "#### Pendulum-v0 environment:\n",
    "<img src=\"pendulum.png\" width=\"300\">\n",
    "\n",
    "#### Halfcheetah-v2 environment:\n",
    "<img src=\"half_cheetah.png\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment for Actor Critic\n",
    "- inline plotting\n",
    "- gym\n",
    "- directory for logging videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "#environment\n",
    "import gym\n",
    "import os\n",
    "import time\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "logging_interval = 100\n",
    "animate_interval = logging_interval * 5\n",
    "logdir='./DDPG/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up gym environment\n",
    "The code below does the following for you:\n",
    "- Wrap environment, log videos, setup CUDA variables (if GPU is available)\n",
    "- Record action and observation space dimensions\n",
    "- Fix random seed for determinisitic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-15 12:07:38,448] Making new env: InvertedPendulum-v1\n",
      "[2018-05-15 12:07:38,454] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "VISUALIZE = True\n",
    "SEED = 0\n",
    "MAX_PATH_LENGTH = 500\n",
    "NUM_EPISODES = 12000\n",
    "GAMMA=0.99\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Environments to be tested on\n",
    "env_name = 'InvertedPendulum-v1'\n",
    "# env_name = 'Pendulum-v0'\n",
    "# env_name = 'HalfCheetah-v1' \n",
    "\n",
    "# wrap gym to save videos\n",
    "env = gym.make(env_name)\n",
    "if VISUALIZE:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%logging_interval==0)\n",
    "env._max_episodes_steps = MAX_PATH_LENGTH\n",
    "\n",
    "# check observation and action space\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "if discrete:\n",
    "    print(\"This is a discrete action space, probably not the right algorithm to use\")\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# make variable types for automatic setting to GPU or CPU, depending on GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate your understanding of the simulation:\n",
    "For the environments mentioned above ('Pendulum-v0', 'HalfCheetah-v2', 'InvertedPendulum-v2'),\n",
    "- describe the reward system\n",
    "- describe the each state variable (observation space)\n",
    "- describe the action space\n",
    "- when is the environment considered \"solved\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement an action normalization class:\n",
    "To train across various environments, it is useful to normalize action inputs and outputs between [-1, 1]. This class should take in actions and implement forward and reverse functions to map actions between [-1, 1] and [action_space.low, action_space.high].\n",
    "\n",
    "Using the following gym wrapper, implement this class.\n",
    "- https://github.com/openai/gym/blob/78c416ef7bc829ce55b404b6604641ba0cf47d10/gym/core.py\n",
    "- i.e. we are overriding the outputs scale of actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeAction(gym.ActionWrapper):\n",
    "    def action(self, act):\n",
    "        # [-1, 1] => [action_space.low, action_space.high]\n",
    "        #tanh outputs (-1,1) from tanh, need to be [action_space.low, action_space.high]\n",
    "        act = (act + 1)/2  #[-1, 1] => [0,1]\n",
    "        act = act * (self.action_space.high - self.action_space.low)\n",
    "        act = act + self.action_space.low\n",
    "        return act\n",
    "    \n",
    "    def reverse_action(self, act):\n",
    "        # [action_space.low, action_space.high] => [-1,1]\n",
    "        #reverse of that above\n",
    "        act = act - self.action_space.low\n",
    "        act = act / (self.action_space.high - self.action_space.low)\n",
    "        act = act * 2 - 1\n",
    "        return act\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a weight syncing function\n",
    "In contrast to DQN, DDPG uses soft weight sychronization. At each time step following training, the actor and critic target network weights are updated to track the rollout networks. \n",
    "- target_network.weights <= target_network.weights \\* (1 - tau) + source_network.weights \\* (tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightSync(target_model, source_model, tau = 0.001):\n",
    "    # soft update\n",
    "    for parameter_target, parameter_source in zip(target_model.parameters(), source_model.parameters()):\n",
    "        parameter_target.data.copy_((1 - tau) * parameter_target.data + tau * parameter_source.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Replay class that includes all the functionality of a replay buffer\n",
    "DDPG is an off policy actor-critic method and an identical replay buffer to that used for the previous assignment is applicable here as well (do not include the generate_minibatch method in your Replay class this time). Like before, your constructor for Replay should create an initial buffer of size 1000 when you instantiate it.\n",
    "\n",
    "The replay buffer should kept to some maximum size (60000), allow adding of samples and returning of samples at random from the buffer. Each sample (or experience) is formed as (state, action, reward, next_state, done). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay():\n",
    "    def __init__(self):\n",
    "        self.capacity = 60000\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        self.gamma = 0.99\n",
    "\n",
    "    def initialize(self, init_length, envir):\n",
    "        st = envir.reset()\n",
    "        for _ in range(init_length):\n",
    "            a = envir.action_space.sample()\n",
    "            st1, r, done, info = envir.step(a)\n",
    "            # normalizing action \n",
    "            # [action_space.low, action_space.high] => [-1,1]\n",
    "            a = envir.reverse_action(a)\n",
    "            self.push((st, a, st1, r, done))\n",
    "            if done: st = envir.reset()\n",
    "            else : st = st1\n",
    "                \n",
    "    def push(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def generateMinibatch(self, batch_size):\n",
    "        batch_memory = random.sample(self.memory, batch_size) #return a list\n",
    "        batch_memory = list(zip(*batch_memory))\n",
    "        \n",
    "        batch_st = Variable(FloatTensor(batch_memory[0]))\n",
    "        batch_at = Variable(FloatTensor(batch_memory[1]))\n",
    "        batch_st1 = Variable(FloatTensor(batch_memory[2]))\n",
    "        batch_r = Variable(torch.unsqueeze(FloatTensor(batch_memory[3]),1))\n",
    "        batch_done = torch.unsqueeze(FloatTensor(batch_memory[4]),1)\n",
    "        \n",
    "        return batch_st, batch_at, batch_st1, batch_r, batch_done\n",
    "        \n",
    "    def __len__(self):            \n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Ornstein Uhlenbeck process class for exploration noise\n",
    "The proccess is described here:\n",
    "- https://en.wikipedia.org/wiki/Ornsteinâ€“Uhlenbeck_process\n",
    "- http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "\n",
    "You should implement:\n",
    "- a step / sample method\n",
    "- reset method\n",
    "\n",
    "Use theta = 0.25, mu = 0, sigma = 0.05, dt = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckProcess():\n",
    "    def __init__(self, mu=np.zeros(act_dim), sigma=0.3, theta=.15, dimension=1e-2, x0=None,num_steps=12000):\n",
    "    # for inverted pendulum and pendulum above\n",
    "#     def __init__(self, mu=np.zeros(act_dim), sigma=0.05, theta=.15, dimension=1e-2, x0=None,num_steps=12000):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dimension\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "        \n",
    "    def step(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Deep Neural Network class that creates a dense network of a desired architecture for actor and critic networks\n",
    "\n",
    "\n",
    "#### Actor\n",
    "- input and hidden layer activation function: ReLU\n",
    "\n",
    "- output activation function: Tanh\n",
    "\n",
    "- hidden_state sizes: 400\n",
    "\n",
    "- state and action sizes: variable\n",
    "\n",
    "- number of hidden layers: 2\n",
    "\n",
    "- batch normalization applied to all hidden layers\n",
    "\n",
    "- weight initialization: normal distribution with small variance. \n",
    "\n",
    "#### Critic\n",
    "- input and hidden layer activation function: ReLU\n",
    "\n",
    "- output activation function: None\n",
    "\n",
    "- hidden_state sizes: 300, 300 + action size\n",
    "\n",
    "- state and action sizes: variable\n",
    "\n",
    "- number of hidden layers: 2\n",
    "\n",
    "- batch normalization applied to all hidden layers prior to the action input\n",
    "\n",
    "- weight initialization: normal distribution with small variance.\n",
    "\n",
    "Good baselines can be found in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# actor model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 2 hidden layers, 400 units per layer, tanh output to bound outputs between -1 and 1\n",
    "\n",
    "class actor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.bn1 = nn.BatchNorm1d(400) # batchnormalization\n",
    "        self.fc2 = nn.Linear(400, 400)\n",
    "        self.bn2 = nn.BatchNorm1d(400) # batchnormalization\n",
    "        self.fc3 = nn.Linear(400, output_size)\n",
    "        \n",
    "        # parameters initialization\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.normal_(self.fc1.bias)\n",
    "        nn.init.normal_(self.fc2.bias)\n",
    "        nn.init.normal_(self.fc3.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)  # turn off for inverted-pendulum -v1\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)  # turn off for inverted-pendulum -v1\n",
    "        \n",
    "        outputs = F.tanh(self.fc3(x))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# critic model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 2 hidden layers, 300 units per layer, ouputs rewards therefore unbounded\n",
    "# Action not to be included until 2nd layer of critic (from paper). Make sure to formulate your critic.forward() accordingly\n",
    "\n",
    "class critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, output_size):\n",
    "        super(critic, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_size, 300)\n",
    "        self.bn1 = nn.BatchNorm1d(300) # batchnormalization\n",
    "        self.fc2 = nn.Linear(300 + action_size, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "\n",
    "        # parameters initialization\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.normal_(self.fc1.bias)\n",
    "        nn.init.normal_(self.fc2.bias)\n",
    "        nn.init.normal_(self.fc3.bias)\n",
    "    \n",
    "    def forward(self, states, actions):\n",
    "        x = F.relu(self.fc1(states))\n",
    "        x = self.bn1(x)  # turn off for inverted-pendulum -v1\n",
    "        x = torch.cat((x, actions), 1) # actions only join at second layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        outputs = self.fc3(x)\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DDPG class to encapsulate definition, rollouts, and training\n",
    "\n",
    "- gamma = 0.99\n",
    "\n",
    "- actor_lr = 1e-4\n",
    "\n",
    "- critic_lr = 1e-3\n",
    "\n",
    "- critic l2 regularization = 1e-2\n",
    "\n",
    "- noise decay\n",
    "\n",
    "- noise class\n",
    "\n",
    "- batch_size = 128\n",
    "\n",
    "- optimizer: Adam\n",
    "\n",
    "- loss (critic): mse\n",
    "\n",
    "Furthermore, you can experiment with action versus parameter space noise. The standard implimentation works with action space noise, howeve parameter space noise has shown to produce excellent results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG:\n",
    "    def __init__(self, obs_dim, act_dim, critic_lr = 1e-3, actor_lr = 1e-4, gamma = GAMMA, batch_size = BATCH_SIZE):\n",
    "        self.gamma = GAMMA\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        \n",
    "        # actor\n",
    "        self.actor = actor(input_size = obs_dim, output_size = act_dim).type(FloatTensor)\n",
    "        self.actor_target = actor(input_size = obs_dim, output_size = act_dim).type(FloatTensor)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "\n",
    "        # critic\n",
    "        self.critic = critic(state_size = obs_dim, action_size = act_dim, output_size = 1).type(FloatTensor)\n",
    "        self.critic_target = critic(state_size = obs_dim, action_size = act_dim, output_size = 1).type(FloatTensor)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizer_actor = torch.optim.Adam(self.actor.parameters(), lr = actor_lr)\n",
    "        self.optimizer_critic = torch.optim.Adam(self.critic.parameters(), lr = critic_lr, weight_decay=1e-2)\n",
    "        \n",
    "        # critic loss\n",
    "        self.critic_loss = nn.MSELoss()\n",
    "        \n",
    "        # noise\n",
    "        self.noise = OrnsteinUhlenbeckProcess(dimension = act_dim, num_steps = NUM_EPISODES)\n",
    "\n",
    "        # replay buffer \n",
    "        self.replayBuffer = Replay()\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        # sample from Replay\n",
    "        b_st, b_at, b_st1, b_r, b_d = self.replayBuffer.generateMinibatch(self.batch_size)\n",
    "\n",
    "        ## update critic (create target for Q function)       \n",
    "        # below is for target actor network\n",
    "        targetActorPredict_b_at1 = self.actor_target(b_st1)\n",
    "        \n",
    "        #below is for target critic network\n",
    "        mask = 1 - b_d   # if done is true, change the target to just reward\n",
    "        batch_Q_next = self.critic_target(b_st1, targetActorPredict_b_at1)\n",
    "        QQ_next = Variable((batch_Q_next.data * mask).view(self.batch_size, 1))\n",
    "        b_Q_critic_target = b_r + self.gamma*(QQ_next)\n",
    "        \n",
    "        \n",
    "        # below is for behavior critic network\n",
    "        b_Q_critic_behaviorQ = self.critic(b_st, b_at)\n",
    "        \n",
    "        ## critic optimizer and backprop step (feed in target and predicted values to self.critic_loss)\n",
    "        critic_loss = self.critic_loss(b_Q_critic_behaviorQ, b_Q_critic_target.detach())\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "        \n",
    "        ## update actor (formulate the loss wrt which actor is updated)\n",
    "        # below is for behavior actor network\n",
    "        b_at_actor_behavior = self.actor(b_st)\n",
    "        # below is for behavior critic network\n",
    "        b_Q_critic_behaviorP = self.critic(b_st, b_at_actor_behavior)\n",
    "\n",
    "        ## actor optimizer and backprop step (loss_actor.backward())\n",
    "        loss_actor = -1. * b_Q_critic_behaviorP\n",
    "        loss_actor = loss_actor.mean()\n",
    "        \n",
    "        self.optimizer_actor.zero_grad()\n",
    "        loss_actor.backward()\n",
    "        self.optimizer_actor.step()\n",
    "\n",
    "        # sychronize target network with fast moving one\n",
    "        weightSync(self.critic_target, self.critic)\n",
    "        weightSync(self.actor_target, self.actor)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of your DDPG object\n",
    "- Print network architectures, confirm they are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor(\n",
      "  (fc1): Linear(in_features=4, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
      "  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=400, out_features=1, bias=True)\n",
      ")\n",
      "critic(\n",
      "  (fc1): Linear(in_features=4, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=301, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ddpg = DDPG(obs_dim = obs_dim, act_dim = act_dim)\n",
    "print(ddpg.actor)\n",
    "print(ddpg.critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DDPG on different environments\n",
    "Early stopping conditions:\n",
    "- avg_val > 500 for \"InvertedPendulum\" \n",
    "- avg_val > -150 for \"Pendulum\" \n",
    "- avg_val > 1500 for \"HalfCheetah\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 0.1 for episode: 0\n",
      "Average value: 0.195 for episode: 1\n",
      "Average value: 0.28525 for episode: 2\n",
      "Average value: 0.3709875 for episode: 3\n",
      "Average value: 0.5024381250000001 for episode: 4\n",
      "Average value: 0.57731621875 for episode: 5\n",
      "Average value: 0.6484504078125 for episode: 6\n",
      "Average value: 0.716027887421875 for episode: 7\n",
      "Average value: 0.8302264930507812 for episode: 8\n",
      "Average value: 0.9387151683982421 for episode: 9\n",
      "Average value: 1.04177940997833 for episode: 10\n",
      "Average value: 1.1396904394794134 for episode: 11\n",
      "Average value: 1.1827059175054428 for episode: 12\n",
      "Average value: 1.2735706216301708 for episode: 13\n",
      "Average value: 1.3598920905486622 for episode: 14\n",
      "Average value: 1.3918974860212292 for episode: 15\n",
      "Average value: 1.4723026117201679 for episode: 16\n",
      "Average value: 1.5486874811341593 for episode: 17\n",
      "Average value: 1.6212531070774512 for episode: 18\n",
      "Average value: 1.6901904517235784 for episode: 19\n",
      "Average value: 1.7556809291373994 for episode: 20\n",
      "Average value: 1.7678968826805295 for episode: 21\n",
      "Average value: 1.779502038546503 for episode: 22\n",
      "Average value: 1.8405269366191779 for episode: 23\n",
      "Average value: 1.898500589788219 for episode: 24\n",
      "Average value: 1.903575560298808 for episode: 25\n",
      "Average value: 1.9583967822838675 for episode: 26\n",
      "Average value: 1.960476943169674 for episode: 27\n",
      "Average value: 1.9624530960111903 for episode: 28\n",
      "Average value: 2.014330441210631 for episode: 29\n",
      "Average value: 2.0636139191500993 for episode: 30\n",
      "Average value: 2.110433223192594 for episode: 31\n",
      "Average value: 2.1549115620329644 for episode: 32\n",
      "Average value: 2.147165983931316 for episode: 33\n",
      "Average value: 2.1898076847347503 for episode: 34\n",
      "Average value: 2.2303173004980126 for episode: 35\n",
      "Average value: 2.218801435473112 for episode: 36\n",
      "Average value: 2.207861363699456 for episode: 37\n",
      "Average value: 2.1974682955144833 for episode: 38\n",
      "Average value: 2.187594880738759 for episode: 39\n",
      "Average value: 2.228215136701821 for episode: 40\n",
      "Average value: 2.2668043798667297 for episode: 41\n",
      "Average value: 2.303464160873393 for episode: 42\n",
      "Average value: 2.288290952829723 for episode: 43\n",
      "Average value: 2.3238764051882366 for episode: 44\n",
      "Average value: 2.3076825849288247 for episode: 45\n",
      "Average value: 2.2922984556823836 for episode: 46\n",
      "Average value: 2.2776835328982643 for episode: 47\n",
      "Average value: 2.3137993562533508 for episode: 48\n",
      "Average value: 2.348109388440683 for episode: 49\n",
      "Average value: 2.330703919018649 for episode: 50\n",
      "Average value: 2.3141687230677164 for episode: 51\n",
      "Average value: 2.2984602869143305 for episode: 52\n",
      "Average value: 2.3335372725686137 for episode: 53\n",
      "Average value: 2.3168604089401827 for episode: 54\n",
      "Average value: 2.3010173884931735 for episode: 55\n",
      "Average value: 2.335966519068515 for episode: 56\n",
      "Average value: 2.319168193115089 for episode: 57\n",
      "Average value: 2.3032097834593346 for episode: 58\n",
      "Average value: 2.2880492942863677 for episode: 59\n",
      "Average value: 2.323646829572049 for episode: 60\n",
      "Average value: 2.3574644880934463 for episode: 61\n",
      "Average value: 2.3895912636887737 for episode: 62\n",
      "Average value: 2.420111700504335 for episode: 63\n",
      "Average value: 2.399106115479118 for episode: 64\n",
      "Average value: 2.429150809705162 for episode: 65\n",
      "Average value: 2.4576932692199036 for episode: 66\n",
      "Average value: 2.4348086057589082 for episode: 67\n",
      "Average value: 2.4130681754709626 for episode: 68\n",
      "Average value: 2.4424147666974143 for episode: 69\n",
      "Average value: 2.4702940283625434 for episode: 70\n",
      "Average value: 2.496779326944416 for episode: 71\n",
      "Average value: 2.521940360597195 for episode: 72\n",
      "Average value: 2.545843342567335 for episode: 73\n",
      "Average value: 2.568551175438968 for episode: 74\n",
      "Average value: 2.5401236166670196 for episode: 75\n",
      "Average value: 2.5631174358336684 for episode: 76\n",
      "Average value: 2.5349615640419847 for episode: 77\n",
      "Average value: 2.5082134858398852 for episode: 78\n",
      "Average value: 2.532802811547891 for episode: 79\n",
      "Average value: 2.5061626709704963 for episode: 80\n",
      "Average value: 2.530854537421971 for episode: 81\n",
      "Average value: 2.5043118105508726 for episode: 82\n",
      "Average value: 2.479096220023329 for episode: 83\n",
      "Average value: 2.4551414090221626 for episode: 84\n",
      "Average value: 2.4823843385710544 for episode: 85\n",
      "Average value: 2.4582651216425018 for episode: 86\n",
      "Average value: 2.4853518655603763 for episode: 87\n",
      "Average value: 2.5110842722823574 for episode: 88\n",
      "Average value: 2.535530058668239 for episode: 89\n",
      "Average value: 2.558753555734827 for episode: 90\n",
      "Average value: 2.580815877948085 for episode: 91\n",
      "Average value: 2.6017750840506806 for episode: 92\n",
      "Average value: 2.6216863298481465 for episode: 93\n",
      "Average value: 2.640602013355739 for episode: 94\n",
      "Average value: 2.658571912687952 for episode: 95\n",
      "Average value: 2.6256433170535547 for episode: 96\n",
      "Average value: 2.6443611512008767 for episode: 97\n",
      "Average value: 2.662143093640833 for episode: 98\n",
      "Average value: 2.629035938958791 for episode: 99\n",
      "Average value: 2.6475841420108512 for episode: 100\n",
      "Average value: 2.6152049349103086 for episode: 101\n",
      "Average value: 2.634444688164793 for episode: 102\n",
      "Average value: 2.652722453756553 for episode: 103\n",
      "Average value: 2.6200863310687255 for episode: 104\n",
      "Average value: 2.5890820145152893 for episode: 105\n",
      "Average value: 2.6096279137895246 for episode: 106\n",
      "Average value: 2.629146518100048 for episode: 107\n",
      "Average value: 2.6476891921950454 for episode: 108\n",
      "Average value: 2.615304732585293 for episode: 109\n",
      "Average value: 2.634539495956028 for episode: 110\n",
      "Average value: 2.6028125211582265 for episode: 111\n",
      "Average value: 2.572671895100315 for episode: 112\n",
      "Average value: 2.5440383003452993 for episode: 113\n",
      "Average value: 2.5168363853280344 for episode: 114\n",
      "Average value: 2.5409945660616327 for episode: 115\n",
      "Average value: 2.513944837758551 for episode: 116\n",
      "Average value: 2.538247595870623 for episode: 117\n",
      "Average value: 2.511335216077092 for episode: 118\n",
      "Average value: 2.5357684552732374 for episode: 119\n",
      "Average value: 2.558980032509575 for episode: 120\n",
      "Average value: 2.581031030884096 for episode: 121\n",
      "Average value: 2.601979479339891 for episode: 122\n",
      "Average value: 2.571880505372896 for episode: 123\n",
      "Average value: 2.593286480104251 for episode: 124\n",
      "Average value: 2.613622156099038 for episode: 125\n",
      "Average value: 2.632941048294086 for episode: 126\n",
      "Average value: 2.6012939958793817 for episode: 127\n",
      "Average value: 2.621229296085412 for episode: 128\n",
      "Average value: 2.640167831281141 for episode: 129\n",
      "Average value: 2.658159439717084 for episode: 130\n",
      "Average value: 2.6252514677312297 for episode: 131\n",
      "Average value: 2.593988894344668 for episode: 132\n",
      "Average value: 2.6142894496274343 for episode: 133\n",
      "Average value: 2.633574977146062 for episode: 134\n",
      "Average value: 2.601896228288759 for episode: 135\n",
      "Average value: 2.621801416874321 for episode: 136\n",
      "Average value: 2.590711346030605 for episode: 137\n",
      "Average value: 2.6111757787290744 for episode: 138\n",
      "Average value: 2.6306169897926206 for episode: 139\n",
      "Average value: 2.5990861403029895 for episode: 140\n",
      "Average value: 2.56913183328784 for episode: 141\n",
      "Average value: 2.590675241623448 for episode: 142\n",
      "Average value: 2.611141479542275 for episode: 143\n",
      "Average value: 2.6305844055651613 for episode: 144\n",
      "Average value: 2.649055185286903 for episode: 145\n",
      "Average value: 2.6166024260225575 for episode: 146\n",
      "Average value: 2.6357723047214296 for episode: 147\n",
      "Average value: 2.653983689485358 for episode: 148\n",
      "Average value: 2.67128450501109 for episode: 149\n",
      "Average value: 2.6877202797605353 for episode: 150\n",
      "Average value: 2.6533342657725085 for episode: 151\n",
      "Average value: 2.670667552483883 for episode: 152\n",
      "Average value: 2.6871341748596884 for episode: 153\n",
      "Average value: 2.652777466116704 for episode: 154\n",
      "Average value: 2.6701385928108685 for episode: 155\n",
      "Average value: 2.686631663170325 for episode: 156\n",
      "Average value: 2.6523000800118086 for episode: 157\n",
      "Average value: 2.669685076011218 for episode: 158\n",
      "Average value: 2.636200822210657 for episode: 159\n",
      "Average value: 2.604390781100124 for episode: 160\n",
      "Average value: 2.574171242045118 for episode: 161\n",
      "Average value: 2.545462679942862 for episode: 162\n",
      "Average value: 2.518189545945719 for episode: 163\n",
      "Average value: 2.5422800686484326 for episode: 164\n",
      "Average value: 2.565166065216011 for episode: 165\n",
      "Average value: 2.58690776195521 for episode: 166\n",
      "Average value: 2.6075623738574496 for episode: 167\n",
      "Average value: 2.577184255164577 for episode: 168\n",
      "Average value: 2.548325042406348 for episode: 169\n",
      "Average value: 2.5209087902860303 for episode: 170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 2.4948633507717286 for episode: 171\n",
      "Average value: 2.520120183233142 for episode: 172\n",
      "Average value: 2.494114174071485 for episode: 173\n",
      "Average value: 2.4694084653679105 for episode: 174\n",
      "Average value: 2.4959380420995148 for episode: 175\n",
      "Average value: 2.471141139994539 for episode: 176\n",
      "Average value: 2.447584082994812 for episode: 177\n",
      "Average value: 2.4252048788450713 for episode: 178\n",
      "Average value: 2.4539446349028173 for episode: 179\n",
      "Average value: 2.4812474031576763 for episode: 180\n",
      "Average value: 2.4571850329997926 for episode: 181\n",
      "Average value: 2.434325781349803 for episode: 182\n",
      "Average value: 2.4626094922823127 for episode: 183\n",
      "Average value: 2.489479017668197 for episode: 184\n",
      "Average value: 2.515005066784787 for episode: 185\n",
      "Average value: 2.4892548134455477 for episode: 186\n",
      "Average value: 2.46479207277327 for episode: 187\n",
      "Average value: 2.4415524691346064 for episode: 188\n",
      "Average value: 2.469474845677876 for episode: 189\n",
      "Average value: 2.496001103393982 for episode: 190\n",
      "Average value: 2.471201048224283 for episode: 191\n",
      "Average value: 2.4976409958130685 for episode: 192\n",
      "Average value: 2.4727589460224153 for episode: 193\n",
      "Average value: 2.4991209987212946 for episode: 194\n",
      "Average value: 2.52416494878523 for episode: 195\n",
      "Average value: 2.4979567013459683 for episode: 196\n",
      "Average value: 2.5230588662786695 for episode: 197\n",
      "Average value: 2.546905922964736 for episode: 198\n",
      "Average value: 2.519560626816499 for episode: 199\n",
      "Average value: 2.493582595475674 for episode: 200\n",
      "Average value: 2.5189034657018903 for episode: 201\n",
      "Average value: 2.492958292416796 for episode: 202\n",
      "Average value: 2.468310377795956 for episode: 203\n",
      "Average value: 2.494894858906158 for episode: 204\n",
      "Average value: 2.52015011596085 for episode: 205\n",
      "Average value: 2.4941426101628075 for episode: 206\n",
      "Average value: 2.5194354796546667 for episode: 207\n",
      "Average value: 2.4934637056719335 for episode: 208\n",
      "Average value: 2.5187905203883365 for episode: 209\n",
      "Average value: 2.5428509943689193 for episode: 210\n",
      "Average value: 2.5157084446504734 for episode: 211\n",
      "Average value: 2.5399230224179496 for episode: 212\n",
      "Average value: 2.562926871297052 for episode: 213\n",
      "Average value: 2.584780527732199 for episode: 214\n",
      "Average value: 2.605541501345589 for episode: 215\n",
      "Average value: 2.6252644262783096 for episode: 216\n",
      "Average value: 2.6440012049643937 for episode: 217\n",
      "Average value: 2.611801144716174 for episode: 218\n",
      "Average value: 2.631211087480365 for episode: 219\n",
      "Average value: 2.6496505331063465 for episode: 220\n",
      "Average value: 2.617168006451029 for episode: 221\n",
      "Average value: 2.5863096061284776 for episode: 222\n",
      "Average value: 2.6069941258220535 for episode: 223\n",
      "Average value: 2.576644419530951 for episode: 224\n",
      "Average value: 2.597812198554403 for episode: 225\n",
      "Average value: 2.5679215886266826 for episode: 226\n",
      "Average value: 2.589525509195348 for episode: 227\n",
      "Average value: 2.6100492337355807 for episode: 228\n",
      "Average value: 2.5795467720488015 for episode: 229\n",
      "Average value: 2.600569433446361 for episode: 230\n",
      "Average value: 2.6205409617740427 for episode: 231\n",
      "Average value: 2.5895139136853405 for episode: 232\n",
      "Average value: 2.610038218001073 for episode: 233\n",
      "Average value: 2.6795363071010194 for episode: 234\n",
      "Average value: 2.695559491745968 for episode: 235\n",
      "Average value: 2.6607815171586697 for episode: 236\n",
      "Average value: 2.6777424413007362 for episode: 237\n",
      "Average value: 2.6938553192356993 for episode: 238\n",
      "Average value: 2.7091625532739143 for episode: 239\n",
      "Average value: 2.7237044256102183 for episode: 240\n",
      "Average value: 2.6875192043297074 for episode: 241\n",
      "Average value: 2.653143244113222 for episode: 242\n",
      "Average value: 2.620486081907561 for episode: 243\n",
      "Average value: 2.6394617778121825 for episode: 244\n",
      "Average value: 2.607488688921573 for episode: 245\n",
      "Average value: 2.627114254475494 for episode: 246\n",
      "Average value: 2.6457585417517193 for episode: 247\n",
      "Average value: 2.663470614664133 for episode: 248\n",
      "Average value: 2.680297083930926 for episode: 249\n",
      "Average value: 2.6462822297343798 for episode: 250\n",
      "Average value: 2.6639681182476607 for episode: 251\n",
      "Average value: 2.6807697123352776 for episode: 252\n",
      "Average value: 2.6967312267185135 for episode: 253\n",
      "Average value: 2.7118946653825877 for episode: 254\n",
      "Average value: 2.676299932113458 for episode: 255\n",
      "Average value: 2.642484935507785 for episode: 256\n",
      "Average value: 2.6603606887323954 for episode: 257\n",
      "Average value: 2.6273426542957754 for episode: 258\n",
      "Average value: 2.6459755215809864 for episode: 259\n",
      "Average value: 2.613676745501937 for episode: 260\n",
      "Average value: 2.58299290822684 for episode: 261\n",
      "Average value: 2.6038432628154977 for episode: 262\n",
      "Average value: 2.6236510996747224 for episode: 263\n",
      "Average value: 2.5924685446909863 for episode: 264\n",
      "Average value: 2.6128451174564367 for episode: 265\n",
      "Average value: 2.582202861583615 for episode: 266\n",
      "Average value: 2.553092718504434 for episode: 267\n",
      "Average value: 2.575438082579212 for episode: 268\n",
      "Average value: 2.5466661784502516 for episode: 269\n",
      "Average value: 2.519332869527739 for episode: 270\n",
      "Average value: 2.4933662260513523 for episode: 271\n",
      "Average value: 2.5186979147487847 for episode: 272\n",
      "Average value: 2.4927630190113454 for episode: 273\n",
      "Average value: 2.518124868060778 for episode: 274\n",
      "Average value: 2.542218624657739 for episode: 275\n",
      "Average value: 2.565107693424852 for episode: 276\n",
      "Average value: 2.5368523087536095 for episode: 277\n",
      "Average value: 2.5600096933159286 for episode: 278\n",
      "Average value: 2.5320092086501322 for episode: 279\n",
      "Average value: 2.5054087482176257 for episode: 280\n",
      "Average value: 2.4801383108067445 for episode: 281\n",
      "Average value: 2.4561313952664072 for episode: 282\n",
      "Average value: 2.433324825503087 for episode: 283\n",
      "Average value: 2.4616585842279326 for episode: 284\n",
      "Average value: 2.438575655016536 for episode: 285\n",
      "Average value: 2.416646872265709 for episode: 286\n",
      "Average value: 2.4458145286524235 for episode: 287\n",
      "Average value: 2.4235238022198025 for episode: 288\n",
      "Average value: 2.4023476121088123 for episode: 289\n",
      "Average value: 2.382230231503372 for episode: 290\n",
      "Average value: 2.3631187199282033 for episode: 291\n",
      "Average value: 2.394962783931793 for episode: 292\n",
      "Average value: 2.375214644735203 for episode: 293\n",
      "Average value: 2.406453912498443 for episode: 294\n",
      "Average value: 2.4361312168735205 for episode: 295\n",
      "Average value: 2.464324656029844 for episode: 296\n",
      "Average value: 2.4411084232283518 for episode: 297\n",
      "Average value: 2.469053002066934 for episode: 298\n",
      "Average value: 2.495600351963587 for episode: 299\n",
      "Average value: 2.520820334365408 for episode: 300\n",
      "Average value: 2.4947793176471373 for episode: 301\n",
      "Average value: 2.4700403517647804 for episode: 302\n",
      "Average value: 2.4465383341765414 for episode: 303\n",
      "Average value: 2.4242114174677143 for episode: 304\n",
      "Average value: 2.4030008465943284 for episode: 305\n",
      "Average value: 2.432850804264612 for episode: 306\n",
      "Average value: 2.4112082640513814 for episode: 307\n",
      "Average value: 2.440647850848812 for episode: 308\n",
      "Average value: 2.4186154583063715 for episode: 309\n",
      "Average value: 2.3976846853910527 for episode: 310\n",
      "Average value: 2.3778004511215003 for episode: 311\n",
      "Average value: 2.358910428565425 for episode: 312\n",
      "Average value: 2.340964907137154 for episode: 313\n",
      "Average value: 2.323916661780296 for episode: 314\n",
      "Average value: 2.357720828691281 for episode: 315\n",
      "Average value: 2.339834787256717 for episode: 316\n",
      "Average value: 2.372843047893881 for episode: 317\n",
      "Average value: 2.354200895499187 for episode: 318\n",
      "Average value: 2.3364908507242275 for episode: 319\n",
      "Average value: 2.369666308188016 for episode: 320\n",
      "Average value: 2.4011829927786152 for episode: 321\n",
      "Average value: 2.3811238431396844 for episode: 322\n",
      "Average value: 2.3620676509827003 for episode: 323\n",
      "Average value: 2.3439642684335653 for episode: 324\n",
      "Average value: 2.326766055011887 for episode: 325\n",
      "Average value: 2.3604277522612924 for episode: 326\n",
      "Average value: 2.3424063646482276 for episode: 327\n",
      "Average value: 2.375286046415816 for episode: 328\n",
      "Average value: 2.4065217440950253 for episode: 329\n",
      "Average value: 2.386195656890274 for episode: 330\n",
      "Average value: 2.41688587404576 for episode: 331\n",
      "Average value: 2.4460415803434716 for episode: 332\n",
      "Average value: 2.473739501326298 for episode: 333\n",
      "Average value: 2.450052526259983 for episode: 334\n",
      "Average value: 2.427549899946984 for episode: 335\n",
      "Average value: 2.406172404949635 for episode: 336\n",
      "Average value: 2.385863784702153 for episode: 337\n",
      "Average value: 2.3665705954670453 for episode: 338\n",
      "Average value: 2.348242065693693 for episode: 339\n",
      "Average value: 2.3808299624090083 for episode: 340\n",
      "Average value: 2.411788464288558 for episode: 341\n",
      "Average value: 2.39119904107413 for episode: 342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 2.3716390890204235 for episode: 343\n",
      "Average value: 2.4030571345694023 for episode: 344\n",
      "Average value: 2.382904277840932 for episode: 345\n",
      "Average value: 2.3637590639488852 for episode: 346\n",
      "Average value: 2.345571110751441 for episode: 347\n",
      "Average value: 2.328292555213869 for episode: 348\n",
      "Average value: 2.3118779274531756 for episode: 349\n",
      "Average value: 2.296284031080517 for episode: 350\n",
      "Average value: 2.281469829526491 for episode: 351\n",
      "Average value: 2.2673963380501663 for episode: 352\n",
      "Average value: 2.254026521147658 for episode: 353\n",
      "Average value: 2.291325195090275 for episode: 354\n",
      "Average value: 2.2767589353357613 for episode: 355\n",
      "Average value: 2.262920988568973 for episode: 356\n",
      "Average value: 2.299774939140524 for episode: 357\n",
      "Average value: 2.284786192183498 for episode: 358\n",
      "Average value: 2.270546882574323 for episode: 359\n",
      "Average value: 2.3070195384456067 for episode: 360\n",
      "Average value: 2.3416685615233264 for episode: 361\n",
      "Average value: 2.32458513344716 for episode: 362\n",
      "Average value: 2.308355876774802 for episode: 363\n",
      "Average value: 2.3429380829360613 for episode: 364\n",
      "Average value: 2.375791178789258 for episode: 365\n",
      "Average value: 2.4070016198497948 for episode: 366\n",
      "Average value: 2.436651538857305 for episode: 367\n",
      "Average value: 2.4148189619144396 for episode: 368\n",
      "Average value: 2.4440780138187175 for episode: 369\n",
      "Average value: 2.4218741131277817 for episode: 370\n",
      "Average value: 2.4007804074713928 for episode: 371\n",
      "Average value: 2.380741387097823 for episode: 372\n",
      "Average value: 2.361704317742932 for episode: 373\n",
      "Average value: 2.3936191018557853 for episode: 374\n",
      "Average value: 2.4239381467629957 for episode: 375\n",
      "Average value: 2.452741239424846 for episode: 376\n",
      "Average value: 2.4301041774536034 for episode: 377\n",
      "Average value: 2.458598968580923 for episode: 378\n",
      "Average value: 2.4856690201518767 for episode: 379\n",
      "Average value: 2.4613855691442827 for episode: 380\n",
      "Average value: 2.4383162906870686 for episode: 381\n",
      "Average value: 2.4664004761527147 for episode: 382\n",
      "Average value: 2.443080452345079 for episode: 383\n",
      "Average value: 2.470926429727825 for episode: 384\n",
      "Average value: 2.4973801082414333 for episode: 385\n",
      "Average value: 2.5225111028293616 for episode: 386\n",
      "Average value: 2.4963855476878933 for episode: 387\n",
      "Average value: 2.471566270303499 for episode: 388\n",
      "Average value: 2.447987956788324 for episode: 389\n",
      "Average value: 2.425588558948908 for episode: 390\n",
      "Average value: 2.4543091310014624 for episode: 391\n",
      "Average value: 2.481593674451389 for episode: 392\n",
      "Average value: 2.4575139907288195 for episode: 393\n",
      "Average value: 2.4346382911923783 for episode: 394\n",
      "Average value: 2.462906376632759 for episode: 395\n",
      "Average value: 2.439761057801121 for episode: 396\n",
      "Average value: 2.417773004911065 for episode: 397\n",
      "Average value: 2.4468843546655115 for episode: 398\n",
      "Average value: 2.4745401369322355 for episode: 399\n",
      "Average value: 2.4508131300856237 for episode: 400\n",
      "Average value: 2.478272473581342 for episode: 401\n",
      "Average value: 2.504358849902275 for episode: 402\n",
      "Average value: 2.479140907407161 for episode: 403\n",
      "Average value: 2.455183862036803 for episode: 404\n",
      "Average value: 2.482424668934963 for episode: 405\n",
      "Average value: 2.5083034354882146 for episode: 406\n",
      "Average value: 2.5328882637138035 for episode: 407\n",
      "Average value: 2.5062438505281133 for episode: 408\n",
      "Average value: 2.480931658001708 for episode: 409\n",
      "Average value: 2.5068850751016223 for episode: 410\n",
      "Average value: 2.531540821346541 for episode: 411\n",
      "Average value: 2.554963780279214 for episode: 412\n",
      "Average value: 2.577215591265253 for episode: 413\n",
      "Average value: 2.59835481170199 for episode: 414\n",
      "Average value: 2.6184370711168903 for episode: 415\n",
      "Average value: 2.587515217561046 for episode: 416\n",
      "Average value: 2.5581394566829934 for episode: 417\n",
      "Average value: 2.5802324838488433 for episode: 418\n",
      "Average value: 2.551220859656401 for episode: 419\n",
      "Average value: 2.523659816673581 for episode: 420\n",
      "Average value: 2.497476825839902 for episode: 421\n",
      "Average value: 2.5226029845479068 for episode: 422\n",
      "Average value: 2.546472835320511 for episode: 423\n",
      "Average value: 2.5691491935544852 for episode: 424\n",
      "Average value: 2.540691733876761 for episode: 425\n",
      "Average value: 2.513657147182923 for episode: 426\n",
      "Average value: 2.5379742898237767 for episode: 427\n",
      "Average value: 2.5110755753325877 for episode: 428\n",
      "Average value: 2.4855217965659584 for episode: 429\n",
      "Average value: 2.51124570673766 for episode: 430\n",
      "Average value: 2.4856834214007772 for episode: 431\n",
      "Average value: 2.4613992503307385 for episode: 432\n",
      "Average value: 2.4383292878142013 for episode: 433\n",
      "Average value: 2.4164128234234914 for episode: 434\n",
      "Average value: 2.445592182252317 for episode: 435\n",
      "Average value: 2.4733125731397005 for episode: 436\n",
      "Average value: 2.4996469444827154 for episode: 437\n",
      "Average value: 2.5246645972585795 for episode: 438\n",
      "Average value: 2.4984313673956504 for episode: 439\n",
      "Average value: 2.523509799025868 for episode: 440\n",
      "Average value: 2.547334309074574 for episode: 441\n",
      "Average value: 2.519967593620845 for episode: 442\n",
      "Average value: 2.543969213939803 for episode: 443\n",
      "Average value: 2.5667707532428126 for episode: 444\n",
      "Average value: 2.5884322155806716 for episode: 445\n",
      "Average value: 2.6090106048016377 for episode: 446\n",
      "Average value: 2.578560074561556 for episode: 447\n",
      "Average value: 2.549632070833478 for episode: 448\n",
      "Average value: 2.572150467291804 for episode: 449\n",
      "Average value: 2.5935429439272135 for episode: 450\n",
      "Average value: 2.6138657967308525 for episode: 451\n",
      "Average value: 2.6331725068943097 for episode: 452\n",
      "Average value: 2.651513881549594 for episode: 453\n",
      "Average value: 2.7189381874721144 for episode: 454\n",
      "Average value: 2.7329912780985084 for episode: 455\n",
      "Average value: 2.796341714193583 for episode: 456\n",
      "Average value: 2.9065246284839037 for episode: 457\n",
      "Average value: 3.0111983970597085 for episode: 458\n",
      "Average value: 3.110638477206723 for episode: 459\n",
      "Average value: 3.2051065533463867 for episode: 460\n",
      "Average value: 3.3948512256790675 for episode: 461\n",
      "Average value: 3.375108664395114 for episode: 462\n",
      "Average value: 3.406353231175358 for episode: 463\n",
      "Average value: 3.63603556961659 for episode: 464\n",
      "Average value: 3.6542337911357605 for episode: 465\n",
      "Average value: 3.821522101578972 for episode: 466\n",
      "Average value: 3.8304459965000235 for episode: 467\n",
      "Average value: 3.8889236966750222 for episode: 468\n",
      "Average value: 3.944477511841271 for episode: 469\n",
      "Average value: 3.9472536362492074 for episode: 470\n",
      "Average value: 3.949890954436747 for episode: 471\n",
      "Average value: 3.9023964067149093 for episode: 472\n",
      "Average value: 3.8572765863791636 for episode: 473\n",
      "Average value: 3.814412757060205 for episode: 474\n",
      "Average value: 3.7736921192071944 for episode: 475\n",
      "Average value: 3.7350075132468343 for episode: 476\n",
      "Average value: 3.7482571375844924 for episode: 477\n",
      "Average value: 3.7108442807052677 for episode: 478\n",
      "Average value: 3.7253020666700043 for episode: 479\n",
      "Average value: 3.6890369633365037 for episode: 480\n",
      "Average value: 3.654585115169678 for episode: 481\n",
      "Average value: 3.6218558594111943 for episode: 482\n",
      "Average value: 3.5907630664406343 for episode: 483\n",
      "Average value: 3.5612249131186022 for episode: 484\n",
      "Average value: 3.533163667462672 for episode: 485\n",
      "Average value: 3.5565054840895383 for episode: 486\n",
      "Average value: 3.528680209885061 for episode: 487\n",
      "Average value: 3.552246199390808 for episode: 488\n",
      "Average value: 3.5246338894212674 for episode: 489\n",
      "Average value: 3.5484021949502043 for episode: 490\n",
      "Average value: 3.520982085202694 for episode: 491\n",
      "Average value: 3.5449329809425594 for episode: 492\n",
      "Average value: 3.5676863318954313 for episode: 493\n",
      "Average value: 3.58930201530066 for episode: 494\n",
      "Average value: 3.5598369145356266 for episode: 495\n",
      "Average value: 3.5818450688088452 for episode: 496\n",
      "Average value: 3.602752815368403 for episode: 497\n",
      "Average value: 3.622615174599983 for episode: 498\n",
      "Average value: 3.5914844158699837 for episode: 499\n",
      "Average value: 3.5619101950764844 for episode: 500\n",
      "Average value: 3.5838146853226602 for episode: 501\n",
      "Average value: 3.6046239510565274 for episode: 502\n",
      "Average value: 3.674392753503701 for episode: 503\n",
      "Average value: 3.690673115828516 for episode: 504\n",
      "Average value: 3.70613946003709 for episode: 505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 3.6208324870352353 for episode: 506\n",
      "Average value: 3.5397908626834735 for episode: 507\n",
      "Average value: 3.7128013195492997 for episode: 508\n",
      "Average value: 3.827161253571835 for episode: 509\n",
      "Average value: 3.785803190893243 for episode: 510\n",
      "Average value: 3.746513031348581 for episode: 511\n",
      "Average value: 3.8091873797811515 for episode: 512\n",
      "Average value: 3.818728010792094 for episode: 513\n",
      "Average value: 3.777791610252489 for episode: 514\n",
      "Average value: 3.8389020297398644 for episode: 515\n",
      "Average value: 3.846956928252871 for episode: 516\n",
      "Average value: 3.9046090818402273 for episode: 517\n",
      "Average value: 4.009378627748216 for episode: 518\n",
      "Average value: 3.958909696360805 for episode: 519\n",
      "Average value: 4.210964211542764 for episode: 520\n",
      "Average value: 4.400416000965627 for episode: 521\n",
      "Average value: 4.630395200917345 for episode: 522\n",
      "Average value: 4.748875440871477 for episode: 523\n",
      "Average value: 4.861431668827903 for episode: 524\n",
      "Average value: 4.9183600853865075 for episode: 525\n",
      "Average value: 5.422442081117182 for episode: 526\n",
      "Average value: 5.601319977061323 for episode: 527\n",
      "Average value: 5.821253978208256 for episode: 528\n",
      "Average value: 6.280191279297843 for episode: 529\n",
      "Average value: 6.616181715332951 for episode: 530\n",
      "Average value: 7.3353726295663035 for episode: 531\n",
      "Average value: 7.218603998087988 for episode: 532\n",
      "Average value: 7.757673798183589 for episode: 533\n",
      "Average value: 8.269790108274409 for episode: 534\n",
      "Average value: 8.356300602860689 for episode: 535\n",
      "Average value: 9.438485572717653 for episode: 536\n",
      "Average value: 10.66656129408177 for episode: 537\n",
      "Average value: 10.483233229377682 for episode: 538\n",
      "Average value: 11.209071567908797 for episode: 539\n",
      "Average value: 12.648617989513356 for episode: 540\n",
      "Average value: 13.666187090037688 for episode: 541\n",
      "Average value: 16.032877735535802 for episode: 542\n",
      "Average value: 19.38123384875901 for episode: 543\n",
      "Average value: 21.31217215632106 for episode: 544\n",
      "Average value: 24.196563548505008 for episode: 545\n",
      "Average value: 25.286735371079757 for episode: 546\n",
      "Average value: 25.57239860252577 for episode: 547\n",
      "Average value: 26.14377867239948 for episode: 548\n",
      "Average value: 26.636589738779506 for episode: 549\n",
      "Average value: 27.85476025184053 for episode: 550\n",
      "Average value: 28.962022239248505 for episode: 551\n",
      "Average value: 31.01392112728608 for episode: 552\n",
      "Average value: 31.563225070921774 for episode: 553\n",
      "Average value: 33.83506381737568 for episode: 554\n",
      "Average value: 36.643310626506896 for episode: 555\n",
      "Average value: 37.31114509518155 for episode: 556\n",
      "Average value: 41.69558784042247 for episode: 557\n",
      "Average value: 42.11080844840134 for episode: 558\n",
      "Average value: 43.105268025981275 for episode: 559\n",
      "Average value: 44.20000462468221 for episode: 560\n",
      "Average value: 44.5900043934481 for episode: 561\n",
      "Average value: 46.21050417377569 for episode: 562\n",
      "Average value: 46.4999789650869 for episode: 563\n",
      "Average value: 47.47498001683255 for episode: 564\n",
      "Average value: 48.05123101599093 for episode: 565\n",
      "Average value: 49.79866946519138 for episode: 566\n",
      "Average value: 50.90873599193181 for episode: 567\n",
      "Average value: 52.86329919233522 for episode: 568\n",
      "Average value: 57.120134232718456 for episode: 569\n",
      "Average value: 61.86412752108253 for episode: 570\n",
      "Average value: 64.8709211450284 for episode: 571\n",
      "Average value: 66.37737508777698 for episode: 572\n",
      "Average value: 68.75850633338813 for episode: 573\n",
      "Average value: 73.62058101671872 for episode: 574\n",
      "Average value: 75.68955196588277 for episode: 575\n",
      "Average value: 84.35507436758863 for episode: 576\n",
      "Average value: 87.18732064920918 for episode: 577\n",
      "Average value: 89.77795461674873 for episode: 578\n",
      "Average value: 88.63905688591129 for episode: 579\n",
      "Average value: 92.10710404161573 for episode: 580\n",
      "Average value: 93.35174883953493 for episode: 581\n",
      "Average value: 93.13416139755819 for episode: 582\n",
      "Average value: 99.82745332768027 for episode: 583\n",
      "Average value: 98.78608066129625 for episode: 584\n",
      "Average value: 98.84677662823144 for episode: 585\n",
      "Average value: 98.75443779681986 for episode: 586\n",
      "Average value: 100.61671590697885 for episode: 587\n",
      "Average value: 100.6358801116299 for episode: 588\n",
      "Average value: 99.7040861060484 for episode: 589\n",
      "Average value: 102.21888180074598 for episode: 590\n",
      "Average value: 100.00793771070867 for episode: 591\n",
      "Average value: 99.55754082517323 for episode: 592\n",
      "Average value: 98.87966378391457 for episode: 593\n",
      "Average value: 102.93568059471883 for episode: 594\n",
      "Average value: 101.1888965649829 for episode: 595\n",
      "Average value: 106.72945173673375 for episode: 596\n",
      "Average value: 105.19297914989706 for episode: 597\n",
      "Average value: 103.98333019240219 for episode: 598\n",
      "Average value: 104.08416368278208 for episode: 599\n",
      "Average value: 108.17995549864297 for episode: 600\n",
      "Average value: 108.17095772371083 for episode: 601\n",
      "Average value: 107.36240983752528 for episode: 602\n",
      "Average value: 111.794289345649 for episode: 603\n",
      "Average value: 109.70457487836656 for episode: 604\n",
      "Average value: 110.41934613444823 for episode: 605\n",
      "Average value: 110.29837882772583 for episode: 606\n",
      "Average value: 108.88345988633952 for episode: 607\n",
      "Average value: 111.43928689202254 for episode: 608\n",
      "Average value: 109.11732254742141 for episode: 609\n",
      "Average value: 107.51145642005032 for episode: 610\n",
      "Average value: 106.9358835990478 for episode: 611\n",
      "Average value: 108.1390894190954 for episode: 612\n",
      "Average value: 106.68213494814063 for episode: 613\n",
      "Average value: 110.5980282007336 for episode: 614\n",
      "Average value: 107.81812679069691 for episode: 615\n",
      "Average value: 111.12722045116206 for episode: 616\n",
      "Average value: 110.47085942860396 for episode: 617\n",
      "Average value: 110.64731645717376 for episode: 618\n",
      "Average value: 115.76495063431507 for episode: 619\n",
      "Average value: 114.52670310259931 for episode: 620\n",
      "Average value: 112.70036794746935 for episode: 621\n",
      "Average value: 119.21534955009588 for episode: 622\n",
      "Average value: 117.00458207259108 for episode: 623\n",
      "Average value: 115.00435296896151 for episode: 624\n",
      "Average value: 113.95413532051343 for episode: 625\n",
      "Average value: 111.80642855448775 for episode: 626\n",
      "Average value: 116.56610712676337 for episode: 627\n",
      "Average value: 123.28780177042519 for episode: 628\n",
      "Average value: 122.82341168190393 for episode: 629\n",
      "Average value: 121.28224109780872 for episode: 630\n",
      "Average value: 119.61812904291828 for episode: 631\n",
      "Average value: 121.58722259077237 for episode: 632\n",
      "Average value: 120.75786146123374 for episode: 633\n",
      "Average value: 120.51996838817205 for episode: 634\n",
      "Average value: 119.09396996876343 for episode: 635\n",
      "Average value: 117.88927147032526 for episode: 636\n",
      "Average value: 115.244807896809 for episode: 637\n",
      "Average value: 113.53256750196853 for episode: 638\n",
      "Average value: 117.0059391268701 for episode: 639\n",
      "Average value: 116.3056421705266 for episode: 640\n",
      "Average value: 114.59036006200026 for episode: 641\n",
      "Average value: 112.36084205890025 for episode: 642\n",
      "Average value: 109.44279995595524 for episode: 643\n",
      "Average value: 109.02065995815747 for episode: 644\n",
      "Average value: 106.0696269602496 for episode: 645\n",
      "Average value: 105.66614561223712 for episode: 646\n",
      "Average value: 103.58283833162525 for episode: 647\n",
      "Average value: 107.80369641504399 for episode: 648\n",
      "Average value: 108.41351159429178 for episode: 649\n",
      "Average value: 107.39283601457718 for episode: 650\n",
      "Average value: 105.22319421384833 for episode: 651\n",
      "Average value: 103.41203450315591 for episode: 652\n",
      "Average value: 105.34143277799811 for episode: 653\n",
      "Average value: 102.5743611390982 for episode: 654\n",
      "Average value: 102.19564308214329 for episode: 655\n",
      "Average value: 101.83586092803613 for episode: 656\n",
      "Average value: 102.99406788163432 for episode: 657\n",
      "Average value: 103.7943644875526 for episode: 658\n",
      "Average value: 108.15464626317497 for episode: 659\n",
      "Average value: 106.79691395001622 for episode: 660\n",
      "Average value: 110.5070682525154 for episode: 661\n",
      "Average value: 111.18171483988962 for episode: 662\n",
      "Average value: 110.57262909789515 for episode: 663\n",
      "Average value: 108.49399764300038 for episode: 664\n",
      "Average value: 108.46929776085037 for episode: 665\n",
      "Average value: 106.39583287280784 for episode: 666\n",
      "Average value: 104.32604122916744 for episode: 667\n",
      "Average value: 112.55973916770907 for episode: 668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 113.13175220932361 for episode: 669\n",
      "Average value: 111.22516459885742 for episode: 670\n",
      "Average value: 117.71390636891454 for episode: 671\n",
      "Average value: 115.32821105046881 for episode: 672\n",
      "Average value: 115.11180049794537 for episode: 673\n",
      "Average value: 114.3062104730481 for episode: 674\n",
      "Average value: 124.2908999493957 for episode: 675\n",
      "Average value: 122.8763549519259 for episode: 676\n",
      "Average value: 124.8325372043296 for episode: 677\n",
      "Average value: 127.14091034411311 for episode: 678\n",
      "Average value: 124.23386482690745 for episode: 679\n",
      "Average value: 123.12217158556207 for episode: 680\n",
      "Average value: 120.36606300628397 for episode: 681\n",
      "Average value: 117.74775985596976 for episode: 682\n",
      "Average value: 116.06037186317127 for episode: 683\n",
      "Average value: 114.7573532700127 for episode: 684\n",
      "Average value: 112.61948560651206 for episode: 685\n",
      "Average value: 112.28851132618645 for episode: 686\n",
      "Average value: 109.47408575987713 for episode: 687\n",
      "Average value: 107.25038147188327 for episode: 688\n",
      "Average value: 104.6878623982891 for episode: 689\n",
      "Average value: 103.70346927837464 for episode: 690\n",
      "Average value: 107.6182958144559 for episode: 691\n",
      "Average value: 106.13738102373311 for episode: 692\n",
      "Average value: 103.68051197254644 for episode: 693\n",
      "Average value: 106.89648637391912 for episode: 694\n",
      "Average value: 107.35166205522316 for episode: 695\n",
      "Average value: 105.284078952462 for episode: 696\n",
      "Average value: 111.0198750048389 for episode: 697\n",
      "Average value: 111.76888125459695 for episode: 698\n",
      "Average value: 109.3804371918671 for episode: 699\n",
      "Average value: 107.31141533227375 for episode: 700\n",
      "Average value: 110.74584456566006 for episode: 701\n",
      "Average value: 120.05855233737705 for episode: 702\n",
      "Average value: 117.2056247205082 for episode: 703\n",
      "Average value: 115.64534348448278 for episode: 704\n",
      "Average value: 126.01307631025864 for episode: 705\n",
      "Average value: 124.0624224947457 for episode: 706\n",
      "Average value: 131.4593013700084 for episode: 707\n",
      "Average value: 135.936336301508 for episode: 708\n",
      "Average value: 143.48951948643258 for episode: 709\n",
      "Average value: 143.16504351211094 for episode: 710\n",
      "Average value: 143.8067913365054 for episode: 711\n",
      "Average value: 141.6164517696801 for episode: 712\n",
      "Average value: 143.1856291811961 for episode: 713\n",
      "Average value: 150.6763477221363 for episode: 714\n",
      "Average value: 147.4925303360295 for episode: 715\n",
      "Average value: 148.26790381922802 for episode: 716\n",
      "Average value: 152.3045086282666 for episode: 717\n",
      "Average value: 159.03928319685326 for episode: 718\n",
      "Average value: 154.78731903701058 for episode: 719\n",
      "Average value: 160.64795308516003 for episode: 720\n",
      "Average value: 180.815555430902 for episode: 721\n",
      "Average value: 179.82477765935693 for episode: 722\n",
      "Average value: 201.58353877638908 for episode: 723\n",
      "Average value: 196.2043618375696 for episode: 724\n",
      "Average value: 191.54414374569112 for episode: 725\n",
      "Average value: 195.66693655840655 for episode: 726\n",
      "Average value: 194.3335897304862 for episode: 727\n",
      "Average value: 194.11691024396188 for episode: 728\n",
      "Average value: 197.11106473176378 for episode: 729\n",
      "Average value: 192.25551149517557 for episode: 730\n",
      "Average value: 199.59273592041677 for episode: 731\n",
      "Average value: 197.01309912439592 for episode: 732\n",
      "Average value: 191.8124441681761 for episode: 733\n",
      "Average value: 189.12182195976732 for episode: 734\n",
      "Average value: 184.76573086177893 for episode: 735\n",
      "Average value: 184.67744431869 for episode: 736\n",
      "Average value: 179.0935721027555 for episode: 737\n",
      "Average value: 178.9888934976177 for episode: 738\n",
      "Average value: 174.13944882273682 for episode: 739\n",
      "Average value: 174.33247638159997 for episode: 740\n",
      "Average value: 173.31585256251995 for episode: 741\n",
      "Average value: 171.45005993439395 for episode: 742\n",
      "Average value: 173.12755693767426 for episode: 743\n",
      "Average value: 172.57117909079054 for episode: 744\n",
      "Average value: 167.942620136251 for episode: 745\n",
      "Average value: 167.94548912943844 for episode: 746\n",
      "Average value: 162.59821467296652 for episode: 747\n",
      "Average value: 166.16830393931818 for episode: 748\n",
      "Average value: 168.65988874235228 for episode: 749\n",
      "Average value: 170.42689430523464 for episode: 750\n",
      "Average value: 181.70554958997292 for episode: 751\n",
      "Average value: 176.82027211047426 for episode: 752\n",
      "Average value: 183.92925850495052 for episode: 753\n",
      "Average value: 183.532795579703 for episode: 754\n",
      "Average value: 182.70615580071782 for episode: 755\n",
      "Average value: 180.5708480106819 for episode: 756\n",
      "Average value: 174.79230561014782 for episode: 757\n",
      "Average value: 169.20269032964043 for episode: 758\n",
      "Average value: 164.6425558131584 for episode: 759\n",
      "Average value: 163.91042802250047 for episode: 760\n",
      "Average value: 160.16490662137542 for episode: 761\n",
      "Average value: 161.45666129030664 for episode: 762\n",
      "Average value: 161.3838282257913 for episode: 763\n",
      "Average value: 157.9146368145017 for episode: 764\n",
      "Average value: 157.8689049737766 for episode: 765\n",
      "Average value: 162.42545972508776 for episode: 766\n",
      "Average value: 164.05418673883338 for episode: 767\n",
      "Average value: 165.3014774018917 for episode: 768\n",
      "Average value: 182.6864035317971 for episode: 769\n",
      "Average value: 178.75208335520725 for episode: 770\n",
      "Average value: 173.41447918744686 for episode: 771\n",
      "Average value: 169.14375522807453 for episode: 772\n",
      "Average value: 170.8365674666708 for episode: 773\n",
      "Average value: 166.49473909333724 for episode: 774\n",
      "Average value: 161.77000213867038 for episode: 775\n",
      "Average value: 156.88150203173683 for episode: 776\n",
      "Average value: 153.48742693014998 for episode: 777\n",
      "Average value: 155.81305558364247 for episode: 778\n",
      "Average value: 153.67240280446035 for episode: 779\n",
      "Average value: 148.73878266423733 for episode: 780\n",
      "Average value: 144.45184353102547 for episode: 781\n",
      "Average value: 140.7792513544742 for episode: 782\n",
      "Average value: 137.8902887867505 for episode: 783\n",
      "Average value: 134.24577434741295 for episode: 784\n",
      "Average value: 131.1834856300423 for episode: 785\n",
      "Average value: 128.97431134854017 for episode: 786\n",
      "Average value: 129.97559578111316 for episode: 787\n",
      "Average value: 132.47681599205748 for episode: 788\n",
      "Average value: 129.2029751924546 for episode: 789\n",
      "Average value: 125.94282643283186 for episode: 790\n",
      "Average value: 123.19568511119026 for episode: 791\n",
      "Average value: 120.03590085563074 for episode: 792\n",
      "Average value: 117.5341058128492 for episode: 793\n",
      "Average value: 114.35740052220675 for episode: 794\n",
      "Average value: 112.23953049609639 for episode: 795\n",
      "Average value: 110.62755397129156 for episode: 796\n",
      "Average value: 109.34617627272698 for episode: 797\n",
      "Average value: 107.42886745909063 for episode: 798\n",
      "Average value: 104.5074240861361 for episode: 799\n",
      "Average value: 101.93205288182929 for episode: 800\n",
      "Average value: 100.28545023773782 for episode: 801\n",
      "Average value: 97.97117772585092 for episode: 802\n",
      "Average value: 96.82261883955837 for episode: 803\n",
      "Average value: 95.23148789758045 for episode: 804\n",
      "Average value: 94.36991350270144 for episode: 805\n",
      "Average value: 93.30141782756637 for episode: 806\n",
      "Average value: 91.53634693618805 for episode: 807\n",
      "Average value: 91.05952958937864 for episode: 808\n",
      "Average value: 95.8065531099097 for episode: 809\n",
      "Average value: 99.96622545441421 for episode: 810\n",
      "Average value: 101.5179141816935 for episode: 811\n",
      "Average value: 99.59201847260883 for episode: 812\n",
      "Average value: 97.66241754897838 for episode: 813\n",
      "Average value: 95.62929667152946 for episode: 814\n",
      "Average value: 94.69783183795298 for episode: 815\n",
      "Average value: 93.26294024605532 for episode: 816\n",
      "Average value: 91.59979323375255 for episode: 817\n",
      "Average value: 95.01980357206492 for episode: 818\n",
      "Average value: 92.61881339346166 for episode: 819\n",
      "Average value: 91.88787272378859 for episode: 820\n",
      "Average value: 95.09347908759915 for episode: 821\n",
      "Average value: 98.18880513321918 for episode: 822\n",
      "Average value: 97.12936487655821 for episode: 823\n",
      "Average value: 103.1728966327303 for episode: 824\n",
      "Average value: 102.01425180109378 for episode: 825\n",
      "Average value: 99.71353921103908 for episode: 826\n",
      "Average value: 103.17786225048712 for episode: 827\n",
      "Average value: 101.31896913796275 for episode: 828\n",
      "Average value: 103.00302068106461 for episode: 829\n",
      "Average value: 101.20286964701137 for episode: 830\n",
      "Average value: 99.7927261646608 for episode: 831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 100.90308985642775 for episode: 832\n",
      "Average value: 99.75793536360636 for episode: 833\n",
      "Average value: 99.52003859542604 for episode: 834\n",
      "Average value: 97.29403666565474 for episode: 835\n",
      "Average value: 95.62933483237201 for episode: 836\n",
      "Average value: 94.9478680907534 for episode: 837\n",
      "Average value: 93.45047468621573 for episode: 838\n",
      "Average value: 93.62795095190494 for episode: 839\n",
      "Average value: 92.24655340430968 for episode: 840\n",
      "Average value: 92.83422573409419 for episode: 841\n",
      "Average value: 91.49251444738947 for episode: 842\n",
      "Average value: 90.36788872502 for episode: 843\n",
      "Average value: 93.549494288769 for episode: 844\n",
      "Average value: 94.62201957433054 for episode: 845\n",
      "Average value: 93.09091859561401 for episode: 846\n",
      "Average value: 92.6863726658333 for episode: 847\n",
      "Average value: 92.15205403254163 for episode: 848\n",
      "Average value: 93.84445133091454 for episode: 849\n",
      "Average value: 93.2522287643688 for episode: 850\n",
      "Average value: 92.43961732615034 for episode: 851\n",
      "Average value: 95.31763645984282 for episode: 852\n",
      "Average value: 99.25175463685068 for episode: 853\n",
      "Average value: 97.68916690500815 for episode: 854\n",
      "Average value: 95.65470855975774 for episode: 855\n",
      "Average value: 93.92197313176985 for episode: 856\n",
      "Average value: 93.32587447518135 for episode: 857\n",
      "Average value: 92.40958075142228 for episode: 858\n",
      "Average value: 91.73910171385117 for episode: 859\n",
      "Average value: 91.2021466281586 for episode: 860\n",
      "Average value: 90.89203929675067 for episode: 861\n",
      "Average value: 90.14743733191312 for episode: 862\n",
      "Average value: 89.59006546531747 for episode: 863\n",
      "Average value: 87.96056219205158 for episode: 864\n",
      "Average value: 86.71253408244901 for episode: 865\n",
      "Average value: 85.92690737832655 for episode: 866\n",
      "Average value: 89.28056200941022 for episode: 867\n",
      "Average value: 92.71653390893971 for episode: 868\n",
      "Average value: 90.83070721349272 for episode: 869\n",
      "Average value: 90.58917185281807 for episode: 870\n",
      "Average value: 89.70971326017717 for episode: 871\n",
      "Average value: 92.5742275971683 for episode: 872\n",
      "Average value: 93.69551621730989 for episode: 873\n",
      "Average value: 92.41074040644439 for episode: 874\n",
      "Average value: 90.79020338612217 for episode: 875\n",
      "Average value: 90.70069321681606 for episode: 876\n",
      "Average value: 89.31565855597526 for episode: 877\n",
      "Average value: 87.84987562817649 for episode: 878\n",
      "Average value: 86.70738184676766 for episode: 879\n",
      "Average value: 86.42201275442928 for episode: 880\n",
      "Average value: 85.50091211670781 for episode: 881\n",
      "Average value: 85.02586651087242 for episode: 882\n",
      "Average value: 83.7245731853288 for episode: 883\n",
      "Average value: 87.68834452606235 for episode: 884\n",
      "Average value: 86.60392729975922 for episode: 885\n",
      "Average value: 93.72373093477125 for episode: 886\n",
      "Average value: 91.93754438803269 for episode: 887\n",
      "Average value: 90.29066716863106 for episode: 888\n",
      "Average value: 88.9761338101995 for episode: 889\n",
      "Average value: 87.77732711968952 for episode: 890\n",
      "Average value: 94.88846076370504 for episode: 891\n",
      "Average value: 93.44403772551978 for episode: 892\n",
      "Average value: 91.37183583924377 for episode: 893\n",
      "Average value: 102.80324404728158 for episode: 894\n",
      "Average value: 100.9630818449175 for episode: 895\n",
      "Average value: 98.81492775267162 for episode: 896\n",
      "Average value: 97.77418136503805 for episode: 897\n",
      "Average value: 99.33547229678614 for episode: 898\n",
      "Average value: 97.26869868194683 for episode: 899\n",
      "Average value: 95.10526374784949 for episode: 900\n",
      "Average value: 93.35000056045702 for episode: 901\n",
      "Average value: 92.38250053243416 for episode: 902\n",
      "Average value: 90.51337550581245 for episode: 903\n",
      "Average value: 90.63770673052183 for episode: 904\n",
      "Average value: 89.80582139399573 for episode: 905\n",
      "Average value: 92.46553032429594 for episode: 906\n",
      "Average value: 90.74225380808114 for episode: 907\n",
      "Average value: 89.60514111767709 for episode: 908\n",
      "Average value: 92.87488406179324 for episode: 909\n",
      "Average value: 92.68113985870357 for episode: 910\n",
      "Average value: 91.24708286576839 for episode: 911\n",
      "Average value: 89.98472872247997 for episode: 912\n",
      "Average value: 93.03549228635596 for episode: 913\n",
      "Average value: 92.08371767203816 for episode: 914\n",
      "Average value: 90.17953178843625 for episode: 915\n",
      "Average value: 90.42055519901443 for episode: 916\n",
      "Average value: 88.9995274390637 for episode: 917\n",
      "Average value: 88.24955106711052 for episode: 918\n",
      "Average value: 86.53707351375499 for episode: 919\n",
      "Average value: 85.41021983806723 for episode: 920\n",
      "Average value: 85.48970884616386 for episode: 921\n",
      "Average value: 84.56522340385567 for episode: 922\n",
      "Average value: 82.9869622336629 for episode: 923\n",
      "Average value: 82.63761412197974 for episode: 924\n",
      "Average value: 81.65573341588075 for episode: 925\n",
      "Average value: 83.07294674508671 for episode: 926\n",
      "Average value: 82.51929940783236 for episode: 927\n",
      "Average value: 81.69333443744074 for episode: 928\n",
      "Average value: 86.5586677155687 for episode: 929\n",
      "Average value: 88.38073432979027 for episode: 930\n",
      "Average value: 87.51169761330075 for episode: 931\n",
      "Average value: 86.4361127326357 for episode: 932\n",
      "Average value: 85.51430709600392 for episode: 933\n",
      "Average value: 83.73859174120372 for episode: 934\n",
      "Average value: 82.65166215414352 for episode: 935\n",
      "Average value: 81.11907904643634 for episode: 936\n",
      "Average value: 80.46312509411453 for episode: 937\n",
      "Average value: 79.38996883940881 for episode: 938\n",
      "Average value: 86.37047039743837 for episode: 939\n",
      "Average value: 86.25194687756645 for episode: 940\n",
      "Average value: 84.93934953368813 for episode: 941\n",
      "Average value: 83.54238205700372 for episode: 942\n",
      "Average value: 84.46526295415353 for episode: 943\n",
      "Average value: 83.49199980644585 for episode: 944\n",
      "Average value: 82.01739981612356 for episode: 945\n",
      "Average value: 81.01652982531736 for episode: 946\n",
      "Average value: 79.7657033340515 for episode: 947\n",
      "Average value: 79.27741816734891 for episode: 948\n",
      "Average value: 78.26354725898146 for episode: 949\n",
      "Average value: 77.5503698960324 for episode: 950\n",
      "Average value: 76.42285140123077 for episode: 951\n",
      "Average value: 75.40170883116923 for episode: 952\n",
      "Average value: 74.48162338961076 for episode: 953\n",
      "Average value: 73.30754222013022 for episode: 954\n",
      "Average value: 72.5421651091237 for episode: 955\n",
      "Average value: 71.86505685366751 for episode: 956\n",
      "Average value: 71.52180401098413 for episode: 957\n",
      "Average value: 70.59571381043493 for episode: 958\n",
      "Average value: 70.91592811991318 for episode: 959\n",
      "Average value: 70.62013171391752 for episode: 960\n",
      "Average value: 70.78912512822164 for episode: 961\n",
      "Average value: 69.99966887181056 for episode: 962\n",
      "Average value: 69.84968542822001 for episode: 963\n",
      "Average value: 69.05720115680901 for episode: 964\n",
      "Average value: 68.25434109896857 for episode: 965\n",
      "Average value: 67.79162404402014 for episode: 966\n",
      "Average value: 67.30204284181913 for episode: 967\n",
      "Average value: 66.98694069972817 for episode: 968\n",
      "Average value: 66.53759366474176 for episode: 969\n",
      "Average value: 66.16071398150467 for episode: 970\n",
      "Average value: 65.55267828242944 for episode: 971\n",
      "Average value: 65.12504436830797 for episode: 972\n",
      "Average value: 65.36879214989256 for episode: 973\n",
      "Average value: 65.15035254239793 for episode: 974\n",
      "Average value: 64.94283491527803 for episode: 975\n",
      "Average value: 64.19569316951413 for episode: 976\n",
      "Average value: 63.68590851103842 for episode: 977\n",
      "Average value: 63.551613085486494 for episode: 978\n",
      "Average value: 64.02403243121216 for episode: 979\n",
      "Average value: 63.872830809651546 for episode: 980\n",
      "Average value: 62.929189269168965 for episode: 981\n",
      "Average value: 63.082729805710514 for episode: 982\n",
      "Average value: 62.82859331542498 for episode: 983\n",
      "Average value: 63.68716364965373 for episode: 984\n",
      "Average value: 63.202805467171046 for episode: 985\n",
      "Average value: 62.89266519381249 for episode: 986\n",
      "Average value: 62.54803193412186 for episode: 987\n",
      "Average value: 62.62063033741577 for episode: 988\n",
      "Average value: 63.48959882054498 for episode: 989\n",
      "Average value: 63.41511887951773 for episode: 990\n",
      "Average value: 63.19436293554184 for episode: 991\n",
      "Average value: 63.58464478876474 for episode: 992\n",
      "Average value: 63.455412549326496 for episode: 993\n",
      "Average value: 62.98264192186017 for episode: 994\n",
      "Average value: 63.43350982576716 for episode: 995\n",
      "Average value: 64.1118343344788 for episode: 996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 64.10624261775486 for episode: 997\n",
      "Average value: 64.0009304868671 for episode: 998\n",
      "Average value: 64.25088396252374 for episode: 999\n",
      "Average value: 64.93833976439755 for episode: 1000\n",
      "Average value: 64.59142277617768 for episode: 1001\n",
      "Average value: 64.3618516373688 for episode: 1002\n",
      "Average value: 64.24375905550036 for episode: 1003\n",
      "Average value: 65.73157110272534 for episode: 1004\n",
      "Average value: 65.69499254758907 for episode: 1005\n",
      "Average value: 65.7602429202096 for episode: 1006\n",
      "Average value: 66.97223077419912 for episode: 1007\n",
      "Average value: 66.97361923548915 for episode: 1008\n",
      "Average value: 66.72493827371468 for episode: 1009\n",
      "Average value: 70.28869136002895 for episode: 1010\n",
      "Average value: 69.9742567920275 for episode: 1011\n",
      "Average value: 69.37554395242613 for episode: 1012\n",
      "Average value: 69.20676675480482 for episode: 1013\n",
      "Average value: 68.99642841706458 for episode: 1014\n",
      "Average value: 68.24660699621136 for episode: 1015\n",
      "Average value: 68.43427664640078 for episode: 1016\n",
      "Average value: 68.31256281408074 for episode: 1017\n",
      "Average value: 68.64693467337669 for episode: 1018\n",
      "Average value: 68.91458793970786 for episode: 1019\n",
      "Average value: 68.71885854272246 for episode: 1020\n",
      "Average value: 68.68291561558634 for episode: 1021\n",
      "Average value: 68.04876983480702 for episode: 1022\n",
      "Average value: 68.34633134306667 for episode: 1023\n",
      "Average value: 68.17901477591333 for episode: 1024\n",
      "Average value: 68.42006403711767 for episode: 1025\n",
      "Average value: 67.89906083526179 for episode: 1026\n",
      "Average value: 68.15410779349871 for episode: 1027\n",
      "Average value: 67.59640240382376 for episode: 1028\n",
      "Average value: 66.86658228363257 for episode: 1029\n",
      "Average value: 75.72325316945094 for episode: 1030\n",
      "Average value: 79.03709051097839 for episode: 1031\n",
      "Average value: 78.38523598542946 for episode: 1032\n",
      "Average value: 77.71597418615798 for episode: 1033\n",
      "Average value: 76.98017547685008 for episode: 1034\n",
      "Average value: 75.58116670300757 for episode: 1035\n",
      "Average value: 74.85210836785718 for episode: 1036\n",
      "Average value: 74.70950294946432 for episode: 1037\n",
      "Average value: 79.3740278019911 for episode: 1038\n",
      "Average value: 79.25532641189155 for episode: 1039\n",
      "Average value: 78.94256009129697 for episode: 1040\n",
      "Average value: 77.99543208673212 for episode: 1041\n",
      "Average value: 77.09566048239552 for episode: 1042\n",
      "Average value: 76.44087745827574 for episode: 1043\n",
      "Average value: 80.31883358536194 for episode: 1044\n",
      "Average value: 79.20289190609385 for episode: 1045\n",
      "Average value: 78.14274731078916 for episode: 1046\n",
      "Average value: 77.63560994524971 for episode: 1047\n",
      "Average value: 76.35382944798722 for episode: 1048\n",
      "Average value: 75.08613797558786 for episode: 1049\n",
      "Average value: 74.08183107680847 for episode: 1050\n",
      "Average value: 73.42773952296804 for episode: 1051\n",
      "Average value: 73.15635254681963 for episode: 1052\n",
      "Average value: 72.49853491947864 for episode: 1053\n",
      "Average value: 71.6736081735047 for episode: 1054\n",
      "Average value: 70.83992776482947 for episode: 1055\n",
      "Average value: 69.997931376588 for episode: 1056\n",
      "Average value: 69.0480348077586 for episode: 1057\n",
      "Average value: 68.69563306737066 for episode: 1058\n",
      "Average value: 68.21085141400214 for episode: 1059\n",
      "Average value: 68.60030884330202 for episode: 1060\n",
      "Average value: 68.57029340113692 for episode: 1061\n",
      "Average value: 68.59177873108007 for episode: 1062\n",
      "Average value: 69.11218979452606 for episode: 1063\n",
      "Average value: 68.95658030479976 for episode: 1064\n",
      "Average value: 68.20875128955977 for episode: 1065\n",
      "Average value: 68.09831372508178 for episode: 1066\n",
      "Average value: 68.8933980388277 for episode: 1067\n",
      "Average value: 67.19872813688632 for episode: 1068\n",
      "Average value: 66.688791730042 for episode: 1069\n",
      "Average value: 66.6043521435399 for episode: 1070\n",
      "Average value: 66.27413453636291 for episode: 1071\n",
      "Average value: 65.76042780954477 for episode: 1072\n",
      "Average value: 66.72240641906753 for episode: 1073\n",
      "Average value: 66.33628609811414 for episode: 1074\n",
      "Average value: 66.11947179320843 for episode: 1075\n",
      "Average value: 65.51349820354801 for episode: 1076\n",
      "Average value: 64.78782329337061 for episode: 1077\n",
      "Average value: 64.74843212870208 for episode: 1078\n",
      "Average value: 64.31101052226697 for episode: 1079\n",
      "Average value: 63.79545999615362 for episode: 1080\n",
      "Average value: 64.40568699634593 for episode: 1081\n",
      "Average value: 63.93540264652864 for episode: 1082\n",
      "Average value: 64.2886325142022 for episode: 1083\n",
      "Average value: 64.0742008884921 for episode: 1084\n",
      "Average value: 63.97049084406749 for episode: 1085\n",
      "Average value: 63.721966301864114 for episode: 1086\n",
      "Average value: 63.485867986770906 for episode: 1087\n",
      "Average value: 63.21157458743236 for episode: 1088\n",
      "Average value: 62.850995858060735 for episode: 1089\n",
      "Average value: 62.708446065157695 for episode: 1090\n",
      "Average value: 62.9730237618998 for episode: 1091\n",
      "Average value: 62.72437257380481 for episode: 1092\n",
      "Average value: 62.788153945114566 for episode: 1093\n",
      "Average value: 62.598746247858834 for episode: 1094\n",
      "Average value: 62.518808935465884 for episode: 1095\n",
      "Average value: 62.392868488692585 for episode: 1096\n",
      "Average value: 63.02322506425795 for episode: 1097\n",
      "Average value: 62.722063811045054 for episode: 1098\n",
      "Average value: 62.385960620492796 for episode: 1099\n",
      "Average value: 62.116662589468156 for episode: 1100\n",
      "Average value: 62.160829459994744 for episode: 1101\n",
      "Average value: 62.30278798699501 for episode: 1102\n",
      "Average value: 62.48764858764525 for episode: 1103\n",
      "Average value: 62.71326615826299 for episode: 1104\n",
      "Average value: 62.27760285034984 for episode: 1105\n",
      "Average value: 62.26372270783234 for episode: 1106\n",
      "Average value: 61.50053657244072 for episode: 1107\n",
      "Average value: 61.17550974381869 for episode: 1108\n",
      "Average value: 61.11673425662775 for episode: 1109\n",
      "Average value: 61.360897543796355 for episode: 1110\n",
      "Average value: 61.192852666606534 for episode: 1111\n",
      "Average value: 61.23321003327621 for episode: 1112\n",
      "Average value: 62.871549531612395 for episode: 1113\n",
      "Average value: 63.17797205503177 for episode: 1114\n",
      "Average value: 63.76907345228018 for episode: 1115\n",
      "Average value: 63.280619779666175 for episode: 1116\n",
      "Average value: 63.21658879068286 for episode: 1117\n",
      "Average value: 62.805759351148716 for episode: 1118\n",
      "Average value: 62.46547138359127 for episode: 1119\n",
      "Average value: 62.342197814411705 for episode: 1120\n",
      "Average value: 61.77508792369112 for episode: 1121\n",
      "Average value: 62.136333527506565 for episode: 1122\n",
      "Average value: 61.529516851131234 for episode: 1123\n",
      "Average value: 61.45304100857467 for episode: 1124\n",
      "Average value: 61.130388958145936 for episode: 1125\n",
      "Average value: 61.123869510238634 for episode: 1126\n",
      "Average value: 60.9176760347267 for episode: 1127\n",
      "Average value: 62.07179223299037 for episode: 1128\n",
      "Average value: 61.66820262134085 for episode: 1129\n",
      "Average value: 61.6347924902738 for episode: 1130\n",
      "Average value: 61.55305286576011 for episode: 1131\n",
      "Average value: 62.325400222472105 for episode: 1132\n",
      "Average value: 63.059130211348496 for episode: 1133\n",
      "Average value: 77.35617370078107 for episode: 1134\n",
      "Average value: 79.98836501574202 for episode: 1135\n",
      "Average value: 79.53894676495491 for episode: 1136\n",
      "Average value: 82.61199942670716 for episode: 1137\n",
      "Average value: 86.9813994553718 for episode: 1138\n",
      "Average value: 95.58232948260321 for episode: 1139\n",
      "Average value: 94.65321300847305 for episode: 1140\n",
      "Average value: 93.22055235804939 for episode: 1141\n",
      "Average value: 91.4095247401469 for episode: 1142\n",
      "Average value: 91.73904850313956 for episode: 1143\n",
      "Average value: 94.85209607798258 for episode: 1144\n",
      "Average value: 96.55949127408346 for episode: 1145\n",
      "Average value: 96.58151671037928 for episode: 1146\n",
      "Average value: 104.10244087486032 for episode: 1147\n",
      "Average value: 109.7473188311173 for episode: 1148\n",
      "Average value: 117.75995288956143 for episode: 1149\n",
      "Average value: 123.12195524508336 for episode: 1150\n",
      "Average value: 127.81585748282919 for episode: 1151\n",
      "Average value: 126.77506460868771 for episode: 1152\n",
      "Average value: 130.28631137825332 for episode: 1153\n",
      "Average value: 130.72199580934063 for episode: 1154\n",
      "Average value: 126.3358960188736 for episode: 1155\n",
      "Average value: 126.51910121792992 for episode: 1156\n",
      "Average value: 130.2431461570334 for episode: 1157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 129.38098884918173 for episode: 1158\n",
      "Average value: 128.91193940672264 for episode: 1159\n",
      "Average value: 127.8663424363865 for episode: 1160\n",
      "Average value: 127.52302531456716 for episode: 1161\n",
      "Average value: 126.7968740488388 for episode: 1162\n",
      "Average value: 126.80703034639686 for episode: 1163\n",
      "Average value: 126.26667882907701 for episode: 1164\n",
      "Average value: 124.90334488762315 for episode: 1165\n",
      "Average value: 121.65817764324198 for episode: 1166\n",
      "Average value: 119.22526876107989 for episode: 1167\n",
      "Average value: 117.81400532302588 for episode: 1168\n",
      "Average value: 118.52330505687458 for episode: 1169\n",
      "Average value: 118.89713980403084 for episode: 1170\n",
      "Average value: 118.5522828138293 for episode: 1171\n",
      "Average value: 118.17466867313782 for episode: 1172\n",
      "Average value: 121.16593523948093 for episode: 1173\n",
      "Average value: 121.80763847750688 for episode: 1174\n",
      "Average value: 119.86725655363153 for episode: 1175\n",
      "Average value: 120.57389372594996 for episode: 1176\n",
      "Average value: 118.84519903965246 for episode: 1177\n",
      "Average value: 120.60293908766982 for episode: 1178\n",
      "Average value: 121.07279213328633 for episode: 1179\n",
      "Average value: 118.41915252662201 for episode: 1180\n",
      "Average value: 117.64819490029092 for episode: 1181\n",
      "Average value: 120.61578515527636 for episode: 1182\n",
      "Average value: 139.73499589751253 for episode: 1183\n",
      "Average value: 138.9982461026369 for episode: 1184\n",
      "Average value: 135.54833379750505 for episode: 1185\n",
      "Average value: 139.1209171076298 for episode: 1186\n",
      "Average value: 167.5148712522483 for episode: 1187\n",
      "Average value: 184.83912768963586 for episode: 1188\n",
      "Average value: 184.29717130515405 for episode: 1189\n",
      "Average value: 196.48231273989634 for episode: 1190\n",
      "Average value: 236.6581971029015 for episode: 1191\n",
      "Average value: 274.8252872477564 for episode: 1192\n",
      "Average value: 311.0840228853686 for episode: 1193\n",
      "Average value: 345.52982174110014 for episode: 1194\n",
      "Average value: 344.7033306540451 for episode: 1195\n",
      "Average value: 377.4681641213428 for episode: 1196\n",
      "Average value: 408.59475591527564 for episode: 1197\n",
      "Average value: 438.16501811951184 for episode: 1198\n",
      "Average value: 429.8567672135363 for episode: 1199\n",
      "Average value: 451.2639288528594 for episode: 1200\n",
      "Average value: 478.7007324102164 for episode: 1201\n",
      "Average value: 504.76569578970555 for episode: 1202\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "env = NormalizeAction(env) # remap action values for the environment\n",
    "avg_val = 0\n",
    "\n",
    "#for plotting\n",
    "running_rewards_ddpg = []\n",
    "step_list_ddpg = []\n",
    "step_counter = 0\n",
    "\n",
    "# set term_condition for early stopping according to environment being used\n",
    "# term_condition = -150 # Pendulum\n",
    "term_condition = 500 # inverted pendulum\n",
    "# term_condition = 1500 # halfcheetah \n",
    "ddpg.replayBuffer.initialize(1000, env)\n",
    "\n",
    "for itr in range(NUM_EPISODES):\n",
    "    state = env.reset() # get initial state\n",
    "    animate_this_episode = (itr % animate_interval == 0) and VISUALIZE\n",
    "    total_reward = 0\n",
    "    while True: # for each episode, we loop each step in this episode\n",
    "        ddpg.noise.reset()\n",
    "        if animate_this_episode:\n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "        # use actor to get action, add ddpg.noise.step() to action\n",
    "        # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back \n",
    "        # to train mode after you're done getting the action\n",
    "        var_state = Variable(torch.unsqueeze(FloatTensor(state),0), requires_grad=False)\n",
    "        ddpg.actor.eval()\n",
    "        cuda_tensor_action = ddpg.actor(var_state)\n",
    "        ddpg.actor.train()\n",
    "        \n",
    "        action = cuda_tensor_action.data[0].cpu().numpy()\n",
    "        action = action + ddpg.noise.step()\n",
    "        # below already include [-1,1] => [action_space.low, action_space.high]\n",
    "        new_state, reward, done, _ = env.step(action) \n",
    "        total_reward += reward\n",
    "        \n",
    "        ddpg.replayBuffer.push((state, action, new_state, reward, done))\n",
    "        # step action, get next state, reward, done (keep track of total_reward)\n",
    "        # populate ddpg.replayBuffer\n",
    "        ddpg.train() ###################### update network (per step) in one episode\n",
    "        step_counter += 1\n",
    "        state = new_state\n",
    "        if done: break\n",
    "\n",
    "    if avg_val > term_condition and itr >100 : break\n",
    "\n",
    "    running_rewards_ddpg.append(total_reward) # return of this episode\n",
    "    step_list_ddpg.append(step_counter)\n",
    "\n",
    "    avg_val = avg_val * 0.95 + 0.05*running_rewards_ddpg[-1]\n",
    "    print(\"Average value: {} for episode: {}\".format(avg_val,itr))\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot rewards over multiple training runs \n",
    "This is provided to generate and plot results for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numpy_ewma_vectorized_v2(data, window):\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "    n = data.shape[0]\n",
    "\n",
    "    pows = alpha_rev**(np.arange(n+1))\n",
    "\n",
    "    scale_arr = 1/pows[:-1]\n",
    "    offset = data[0]*pows[1:]\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Inverted-Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ddpg_inverted_pendulum_reward.npy', running_rewards_ddpg)\n",
    "np.save('ddpg_inverted_pendulum_step.npy', step_list_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "step_list_ddpg = np.array(step_list_ddpg)\n",
    "plt.plot(step_list_ddpg, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# env = NormalizeAction(env) # remap action values for the environment\n",
    "state = env.reset() # get initial state\n",
    "while True: # for each episode, we loop each step in this episode\n",
    "    ddpg.noise.reset()\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # use actor to get action, add ddpg.noise.step() to action\n",
    "    # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back \n",
    "    # to train mode after you're done getting the action\n",
    "    var_state = Variable(torch.unsqueeze(FloatTensor(state),0), requires_grad=False)\n",
    "    \n",
    "    ddpg.actor.eval()\n",
    "    cuda_tensor_action = ddpg.actor(var_state)\n",
    "    action = cuda_tensor_action.data[0].cpu().numpy()\n",
    "    action = action + ddpg.noise.step()\n",
    "    # below already include [-1,1] => [action_space.low, action_space.high]\n",
    "    new_state, reward, done, _ = env.step(action) \n",
    "    # step action, get next state, reward, done (keep track of total_reward)\n",
    "    # populate ddpg.replayBuffer\n",
    "    state = new_state\n",
    "    if done: break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "step_list_ddpg = np.array(step_list_ddpg)\n",
    "plt.plot(step_list_ddpg, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# env = NormalizeAction(env) # remap action values for the environment\n",
    "state = env.reset() # get initial state\n",
    "while True: # for each episode, we loop each step in this episode\n",
    "    ddpg.noise.reset()\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # use actor to get action, add ddpg.noise.step() to action\n",
    "    # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back \n",
    "    # to train mode after you're done getting the action\n",
    "    var_state = Variable(torch.unsqueeze(FloatTensor(state),0), requires_grad=False)\n",
    "    \n",
    "    ddpg.actor.eval()\n",
    "    cuda_tensor_action = ddpg.actor(var_state)\n",
    "    action = cuda_tensor_action.data[0].cpu().numpy()\n",
    "    action = action + ddpg.noise.step()\n",
    "    # below already include [-1,1] => [action_space.low, action_space.high]\n",
    "    new_state, reward, done, _ = env.step(action) \n",
    "    # step action, get next state, reward, done (keep track of total_reward)\n",
    "    # populate ddpg.replayBuffer\n",
    "    state = new_state\n",
    "    if done: break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG HalfCheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "step_list_ddpg = np.array(step_list_ddpg)\n",
    "plt.plot(step_list_ddpg, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# env = NormalizeAction(env) # remap action values for the environment\n",
    "state = env.reset() # get initial state\n",
    "while True: # for each episode, we loop each step in this episode\n",
    "    ddpg.noise.reset()\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # use actor to get action, add ddpg.noise.step() to action\n",
    "    # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back \n",
    "    # to train mode after you're done getting the action\n",
    "    var_state = Variable(torch.unsqueeze(FloatTensor(state),0), requires_grad=False)\n",
    "    \n",
    "    ddpg.actor.eval()\n",
    "    cuda_tensor_action = ddpg.actor(var_state)\n",
    "    action = cuda_tensor_action.data[0].cpu().numpy()\n",
    "    action = action + ddpg.noise.step()\n",
    "    # below already include [-1,1] => [action_space.low, action_space.high]\n",
    "    new_state, reward, done, _ = env.step(action) \n",
    "    # step action, get next state, reward, done (keep track of total_reward)\n",
    "    # populate ddpg.replayBuffer\n",
    "    state = new_state\n",
    "    if done: break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE\n",
    "\n",
    "In this section you will implement REINFORCE, with modifications for batch training. It will be for use on both discrete and continous action spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Parametrization\n",
    "\n",
    "Define a MLP which outputs a distribution over the action preferences given input state. For the discrete case, the MLP outputs the likelihood of each action (softmax) while for the continuous case, the output is the mean and standard deviation parametrizing the normal distribution from which the action is sampled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Policy parametrizing model, MLP\n",
    "# ----------------------------------------------------\n",
    "# 1 or 2 hidden layers with a small number of units per layer (similar to DQN)\n",
    "# use ReLU for hidden layer activations\n",
    "# softmax as activation for output if discrete actions, linear for continuous control\n",
    "# for the continuous case, output_dim=2*act_dim (each act_dim gets a mean and std_dev)\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    # For discrete, it is the number of actions for outputs\n",
    "    # For continuous, it is the dimension of action\n",
    "    def __init__(self, Dim_state, num_outputs, disct):\n",
    "        super(mlp, self).__init__()\n",
    "        self.disct = disct\n",
    "        if self.disct == True:\n",
    "            self.fc1 = nn.Linear(Dim_state, 50)\n",
    "            self.fc2 = nn.Linear(50, 50)\n",
    "            self.fc3 = nn.Linear(50, num_outputs)\n",
    "            # parameters initialization\n",
    "#             nn.init.xavier_normal_(self.fc1.weight)\n",
    "#             nn.init.xavier_normal_(self.fc2.weight)\n",
    "#             nn.init.xavier_normal_(self.fc3.weight)\n",
    "#             nn.init.normal_(self.fc1.bias)\n",
    "#             nn.init.normal_(self.fc2.bias)\n",
    "#             nn.init.normal_(self.fc3.bias)\n",
    "            \n",
    "        else:\n",
    "            self.fc1 = nn.Linear(Dim_state, 50)\n",
    "            self.fc2 = nn.Linear(50, 50)\n",
    "            self.fc_mu = nn.Linear(50, num_outputs)\n",
    "            self.fc_sigma = nn.Linear(50, num_outputs)\n",
    "\n",
    "            \n",
    "            # parameters initialization\n",
    "#             nn.init.xavier_normal_(self.fc1.weight)\n",
    "#             nn.init.xavier_normal_(self.fc2.weight)\n",
    "            \n",
    "#             nn.init.xavier_normal_(self.fc_mu.weight)\n",
    "#             nn.init.xavier_normal_(self.fc_sigma.weight)\n",
    "            \n",
    "#             nn.init.normal_(self.fc1.bias)\n",
    "#             nn.init.normal_(self.fc2.bias)\n",
    "            \n",
    "#             nn.init.normal_(self.fc_mu.bias)\n",
    "#             nn.init.normal_(self.fc_sigma.bias)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.disct == True:\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            actions_prob = F.softmax(x, dim=1)\n",
    "            return actions_prob\n",
    "        else: \n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            \n",
    "            mu = self.fc_mu(x)\n",
    "            sigma = self.fc_sigma(x)\n",
    "            return [mu, sigma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that samples an action from the policy distribtion parameters obtained as output of the MLP. The function should return the action and the log-probability (log_odds) of taking that action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(logit, disct):\n",
    "    # logit is the output of the softmax/linear layer\n",
    "    # discrete is a flag for the environment type\n",
    "    # Hint: use Categorical and Normal from torch.distributions to sample action and get the log-probability\n",
    "    # Note that log_probability in this case translates to ln(\\pi(a|s)) \n",
    "    if disct == True:\n",
    "        action_distribution=torch.distributions.Categorical(logit)\n",
    "        action = action_distribution.sample()\n",
    "        log_odds = action_distribution.log_prob(action)\n",
    "        \n",
    "    else : # continuous \n",
    "        mean = logit[0]\n",
    "        cov = F.softplus(logit[1])\n",
    "        action_distribution = torch.distributions.normal.Normal(mean, cov)\n",
    "        action = action_distribution.sample()\n",
    "        log_odds = action_distribution.log_prob(action)\n",
    "    return action, log_odds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function update_policy that defines the loss function and updates the MLP according to the REINFORCE update rule (ref. slide 24 of Lec 7 or page 330 of Sutton and Barto (2018)). The update algorithm to be used below is slightly different: instead of updating the network at every time-step, we take the gradient of the loss averaged over a batch of timesteps (this is to make SGD more stable). We also use a baseline to reduce variance. \n",
    "\n",
    "The discount factor is set as 1 here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward2go(rewards, gamma =1):\n",
    "    r2g = []\n",
    "    acc_r = 0\n",
    "    for r in reversed(rewards):\n",
    "        acc_r = acc_r * gamma + r\n",
    "        r2g.append(acc_r)\n",
    "    return r2g[::-1]\n",
    "\n",
    "\n",
    "def update_policy(paths, net):\n",
    "    # paths: a list of paths (complete episodes, used to calculate return at each time step)\n",
    "    # net: MLP object\n",
    "    \n",
    "    num_paths = len(paths)\n",
    "    rew_cums = []\n",
    "    log_odds = []\n",
    "    # calculated as \"reward to go\"\n",
    "    \n",
    "    for path in paths:\n",
    "        # rew_cums should record return at each time step for each path\n",
    "        rew_cums += reward2go(path['reward'])\n",
    "        # log_odds should record log_odds obtained at each timestep of path\n",
    "        log_odds += path['log_odds']\n",
    "        # calculated as \"reward to go\" \n",
    "\n",
    "    # make log_odds, rew_cums each a vector\n",
    "    rew_cums = np.array(rew_cums)\n",
    "    log_odds = np.array(log_odds)\n",
    "    rew_cums = (rew_cums - rew_cums.mean()) / (rew_cums.std() + 1e-5) # create baseline\n",
    "    # calculate policy loss and average over paths\n",
    "    policy_loss = -rew_cums.dot(log_odds)/ num_paths\n",
    "    \n",
    "    # take optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment and instantiate objects. Your algorithm is to be tested on one discrete and two continuous environments. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-15 10:10:22,076] Making new env: InvertedPendulum-v1\n",
      "[2018-05-15 10:10:22,092] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/85/185/chs140/ECE276C/PA3/DDPG')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp(\n",
      "  (fc1): Linear(in_features=4, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc_mu): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (fc_sigma): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "# Select Environment\n",
    "\n",
    "######discrete environment:\n",
    "# env_name='CartPole-v0'\n",
    "\n",
    "######continous environments:\n",
    "env_name='InvertedPendulum-v1'\n",
    "#env_name = 'HalfCheetah-v1'\n",
    "\n",
    "\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "visualize = False\n",
    "# animate=visualize\n",
    "learning_rate = 1e-3\n",
    "\n",
    "max_path_length=None\n",
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "\n",
    "# Set random seeds\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# Saving parameters\n",
    "logdir='./REINFORCE/'\n",
    "\n",
    "if visualize:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%animate_interval==0)\n",
    "\n",
    "env._max_episodes_steps = min_timesteps_per_batch\n",
    "\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "\n",
    "# Get observation and action space dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps\n",
    "\n",
    "# Make network object (remember to pass in appropriate flags for the type of action space in use)\n",
    "# net = mlp(*args)\n",
    "net = mlp(Dim_state = obs_dim, num_outputs = act_dim, disct = discrete).type(FloatTensor)\n",
    "\n",
    "# Make optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run REINFORCE\n",
    "\n",
    "Run REINFORCE for CartPole, InvertedPendulum, and HalfCheetah. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\r",
      "Average reward: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-15 10:10:41,725] Finished writing results. You can upload them to the scoreboard via gym.upload('/datasets/home/85/185/chs140/ECE276C/PA3/REINFORCE')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 255.80924724046892\n",
      "done51230330391303\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1000 \n",
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "avg_reward = 0\n",
    "avg_rewards = []\n",
    "step_list_reinforce = []\n",
    "total_steps = 0\n",
    "episodes = 0\n",
    "\n",
    "for itr in range(n_iter): # loop for number of optimization steps\n",
    "    paths = []\n",
    "    steps = 0\n",
    "    while True: # loop to get enough timesteps in this batch --> if episode ends this loop will restart till steps reaches limit\n",
    "        ob = env.reset()   \n",
    "        animate_this_episode = (itr % animate_interval == 0) and visualize\n",
    "        obs, acs, rews, log_odds = [], [], [], [] \n",
    "        obs.append(ob)\n",
    "\n",
    "        while True: # loop for episode inside batch\n",
    "            if animate_this_episode:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "            # get parametrized policy distribution from net using current state ob\n",
    "            net.eval()\n",
    "            var_ob = Variable(torch.unsqueeze(FloatTensor(ob),0), requires_grad=False)\n",
    "            distribution_parameters = net(var_ob)\n",
    "            \n",
    "            net.train()\n",
    "            # sample action and get log-probability (log_odds) from distribution\n",
    "            cuda_tensor_ac, log_odd= sample_action(logit = distribution_parameters , disct = discrete)\n",
    "            ac = cuda_tensor_ac.data[0].cpu().numpy()\n",
    "            \n",
    "            # step environment, record reward, next state\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "            # append to obs, acs, rewards, log_odds\n",
    "            obs.append(ob)\n",
    "            acs.append(ac)\n",
    "            rews.append(rew)\n",
    "            log_odds.append(log_odd)\n",
    "            \n",
    "            # if done, restart episode till min_timesteps_per_batch is reached     \n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                episodes = episodes + 1\n",
    "                break\n",
    "                \n",
    "        path = {\"observation\" : obs, \n",
    "                \"reward\" : np.array(rews), \n",
    "                \"action\" : (acs),\n",
    "                \"log_odds\" : log_odds}\n",
    "        \n",
    "        paths.append(path)\n",
    "        if steps > min_timesteps_per_batch: break \n",
    "\n",
    "    update_policy(paths, net)  # use all complete episodes (a batch of timesteps) recorded in this itr to update net\n",
    "    if itr == 0: avg_reward = path['reward'].sum()\n",
    "        \n",
    "    else: avg_reward = avg_reward * 0.95 + 0.05 * path['reward'].sum()\n",
    "        \n",
    "    if avg_reward > 500: break\n",
    "    # inverted 500, half_cheetah 1500, cartpole 200\n",
    "    total_steps += steps\n",
    "    print(avg_reward,end='\\r')\n",
    "    avg_rewards.append(avg_reward)\n",
    "    step_list_reinforce.append(total_steps)\n",
    "    if itr % logging_interval == 0: print('Average reward: {}'.format(avg_reward))   \n",
    "        \n",
    "env.close()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reinforce_cartpole_reward.npy', avg_rewards)\n",
    "np.save('reinforce_cartpole_step.npy', step_list_reinforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-15 10:00:46,789] Making new env: CartPole-v0\n",
      "[2018-05-15 10:00:46,795] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "env_name='CartPole-v0'\n",
    "\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "visualize = True\n",
    "animate=visualize\n",
    "learning_rate = 1e-3\n",
    "\n",
    "max_path_length=None\n",
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "\n",
    "# Set random seeds\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "# Saving parameters\n",
    "logdir='./REINFORCE/'\n",
    "\n",
    "if visualize:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%animate_interval==0)\n",
    "\n",
    "env._max_episodes_steps = min_timesteps_per_batch\n",
    "\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "# Get observation and action space dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "########### for saving optimal model video\n",
    "\n",
    "ob = env.reset() \n",
    "while True:\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # get parametrized policy distribution from net using current state ob\n",
    "    net.eval()\n",
    "    var_ob = Variable(torch.unsqueeze(FloatTensor(ob),0), requires_grad=False)\n",
    "    distribution_parameters = net(var_ob)\n",
    "    # sample action and get log-probability (log_odds) from distribution\n",
    "    cuda_tensor_ac, log_odd= sample_action(logit = distribution_parameters , disct = discrete)\n",
    "    ac = cuda_tensor_ac.data[0].cpu().numpy()\n",
    "    # step environment, record reward, next state\n",
    "    new_ob, rew, done, _ = env.step(ac)\n",
    "    ob = new_ob\n",
    "    if done: break\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce Inverted Pendulum-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reinforce_inverted_pendulum_reward.npy', avg_rewards)\n",
    "np.save('reinforce_inverted_pendulum_step.npy', step_list_reinforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <Inverted Pendulum> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-15 10:17:45,697] Making new env: InvertedPendulum-v1\n",
      "[2018-05-15 10:17:45,705] Clearing 6 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "env_name='InvertedPendulum-v1'\n",
    "\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "visualize = True\n",
    "animate=visualize\n",
    "learning_rate = 1e-3\n",
    "\n",
    "max_path_length=None\n",
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "\n",
    "# Set random seeds\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "# Saving parameters\n",
    "logdir='./REINFORCE/'\n",
    "\n",
    "if visualize:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%animate_interval==0)\n",
    "\n",
    "env._max_episodes_steps = min_timesteps_per_batch\n",
    "\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "# Get observation and action space dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "########### for saving optimal model video\n",
    "\n",
    "ob = env.reset() \n",
    "while True:\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # get parametrized policy distribution from net using current state ob\n",
    "    net.eval()\n",
    "    var_ob = Variable(torch.unsqueeze(FloatTensor(ob),0), requires_grad=False)\n",
    "    distribution_parameters = net(var_ob)\n",
    "    # sample action and get log-probability (log_odds) from distribution\n",
    "    cuda_tensor_ac, log_odd= sample_action(logit = distribution_parameters , disct = discrete)\n",
    "    ac = cuda_tensor_ac.data[0].cpu().numpy()\n",
    "    # step environment, record reward, next state\n",
    "    new_ob, rew, done, _ = env.step(ac)\n",
    "    ob = new_ob\n",
    "    if done: break\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce HalfCheetah-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reinforce_halfcheetah_reward.npy', avg_rewards)\n",
    "np.save('reinforce_halfcheetah_step.npy', step_list_reinforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='HalfCheetah-v1'\n",
    "\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "visualize = True\n",
    "animate=visualize\n",
    "learning_rate = 1e-3\n",
    "\n",
    "max_path_length=None\n",
    "min_timesteps_per_batch = 2000  # sets the batch size for updating network\n",
    "\n",
    "# Set random seeds\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "# Saving parameters\n",
    "logdir='./REINFORCE/'\n",
    "\n",
    "if visualize:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%animate_interval==0)\n",
    "\n",
    "env._max_episodes_steps = min_timesteps_per_batch\n",
    "\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "# Get observation and action space dimensions\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = env.reset() \n",
    "while True:\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    # get parametrized policy distribution from net using current state ob\n",
    "    net.eval()\n",
    "    var_ob = Variable(torch.unsqueeze(FloatTensor(ob),0), requires_grad=False)\n",
    "    distribution_parameters = net(var_ob)\n",
    "    # sample action and get log-probability (log_odds) from distribution\n",
    "    cuda_tensor_ac, log_odd= sample_action(logit = distribution_parameters , disct = discrete)\n",
    "    ac = cuda_tensor_ac.data[0].cpu().numpy()\n",
    "    # step environment, record reward, next state\n",
    "    new_ob, rew, done, _ = env.step(ac)\n",
    "    ob = new_ob\n",
    "    if done: break\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS (15% extra)\n",
    "\n",
    "Compare average returns for CartPole (discrete action space) when using REINFORCE and DQN. Since in REINFORCE we update the network after a set number of steps instead of after every episode, plot the average rewards as a function of steps rather than episodes for both DQN and REINFORCE. You will need to make minor edits to your DQN code from the previous assignment to record average returns as a function of time_steps.\n",
    "\n",
    "Similarly, compare REINFORCE with DDPG on InvertedPendulum and HalfCheetah using steps for the x-axis.\n",
    "\n",
    "You may use the example code provided below as a reference for the graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 DQN environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-10 20:13:03,308] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    " # import your DQN and format your average returns as defined above\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Create the CartPole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "\n",
    "class Net(nn.Module):\n",
    "# Define your network here\n",
    "    def __init__(self, state_size, action_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.fc1.weight.data.normal_(0, 0.1)   # initialization\n",
    "        self.out = nn.Linear(hidden_size, action_size)\n",
    "        self.out.weight.data.normal_(0, 0.1)   # initialization\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        Qs_actions = self.out(x) # Q value for one state, at different actions\n",
    "        return Qs_actions\n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, learning_rate, state_size, action_size, hidden_size, alpha_decay):\n",
    "        self.LR = learning_rate\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.alpha_decay = alpha_decay\n",
    "        self.model = Net(self.state_size, self.action_size, self.hidden_size)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.LR)\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def learn(self, batch_Q_behavior, batch_Q_target):\n",
    "        loss = self.criterion(batch_Q_behavior, batch_Q_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 DQN replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay():\n",
    "    def __init__(self, max_size):\n",
    "        self.capacity = max_size\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        self.gamma = 0.99\n",
    "\n",
    "    def initialize(self, init_length, envir):\n",
    "        st = env.reset()\n",
    "        for _ in range(init_length):\n",
    "            a = np.random.randint(2, size=1)\n",
    "            st1, r, done, info = env.step(int(a))\n",
    "            self.push((st, a, st1, r, done))\n",
    "            if done: st = env.reset()\n",
    "            else : st = st1\n",
    "            \n",
    "    def push(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def generate_minibatch(self, DQN, targetDQN, batch_size):\n",
    "        \n",
    "        batch_memory = random.sample(self.memory, batch_size) #return a list\n",
    "        batch_memory = list(zip(*batch_memory))\n",
    "        \n",
    "        batch_st = Variable(FloatTensor(batch_memory[0]))\n",
    "        batch_at = Variable(LongTensor(batch_memory[1]))\n",
    "        batch_st1 = Variable(FloatTensor(batch_memory[2]))\n",
    "        batch_r = Variable(torch.unsqueeze(FloatTensor(batch_memory[3]),1))\n",
    "        batch_done = FloatTensor(batch_memory[4])\n",
    "\n",
    "        batch_Q_behavior = DQN.model(batch_st).gather(1, batch_at)\n",
    "        mask = 1. - batch_done\n",
    "        batch_Q_next = targetDQN.model(batch_st1).detach()\n",
    "        \n",
    "        QQ_next = Variable((batch_Q_next.max(1)[0].data * mask).view(batch_size, 1))\n",
    "        batch_Q_target = batch_r + self.gamma*(QQ_next)\n",
    "        return batch_Q_behavior, batch_Q_target\n",
    "         \n",
    "    def __len__(self):            \n",
    "        return len(self.memory)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 DQN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run gpu !\n",
      "Average reward: 37.252340002014066\n",
      "Average reward: 90.21662392735004\n",
      "Average reward: 136.0911559073801\n",
      "Average reward: 114.03852854346641\n",
      "Average reward: 80.83668077454597\n",
      "Average reward: 191.47600351186938\n",
      "Average reward: 199.9253710251429\n",
      "Average reward: 199.41618203324447\n",
      "Average reward: 199.93978452885656\n",
      "Average reward: 197.51373584803193\n",
      "Average reward: 199.9852800004386\n",
      "Average reward: 199.9999128498123\n",
      "Average reward: 199.99999948402458\n",
      "Average reward: 199.99999999694498\n",
      "Average reward: 199.38039046222713\n",
      "Average reward: 199.99633158362627\n",
      "Average reward: 199.91444392629492\n",
      "Average reward: 199.99949346276549\n",
      "Average reward: 199.5507878929079\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01 \n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.shape[0]\n",
    "hidden_size = 64\n",
    "alpha_decay = 0.1\n",
    "batch_size = 500\n",
    "\n",
    "DQN = QNetwork(learning_rate, state_size, action_size, hidden_size, alpha_decay)\n",
    "targetDQN = QNetwork(learning_rate, state_size, action_size, hidden_size, alpha_decay)\n",
    "# set targetDQN weights to DQN weights\n",
    "# for ex. targetDQN.model.weights = DQN.model.weights (syntax given here is for representation purpose only)\n",
    "targetDQN.model.load_state_dict(DQN.model.state_dict())\n",
    "replay = Replay(max_size=10000) ## Initialize Replay Buffer\n",
    "replay.initialize(init_length=1000, envir=env) ## Populate the initial experience buffer\n",
    "if use_cuda:\n",
    "    print('run gpu !')\n",
    "    targetDQN.model.cuda()\n",
    "    DQN.model.cuda()\n",
    "else: \n",
    "    print('gpu not activited !')\n",
    "    \n",
    "# Runtime parameters\n",
    "num_episodes = 2000            # max number of episodes to learn from\n",
    "gamma = 0.99                   # future reward discount\n",
    "max_steps = 500                # cut off simulation after this many steps\n",
    "# Exploration parameters\n",
    "min_epsilon = 0.01             # minimum exploration probability\n",
    "decay_rate = 5/num_episodes    # exponential decay rate for exploration prob\n",
    "returns = np.zeros(num_episodes)\n",
    "step_list_DQN = []\n",
    "total_steps = 0\n",
    "avg_reward = 0\n",
    "avg_rewards = []\n",
    "logging_interval = 100\n",
    "\n",
    "\n",
    "for ep in range(1, num_episodes): # ep now is for one iteration\n",
    "    paths = []\n",
    "    steps = 0\n",
    "    while True: #  paths = a number of episode, but restricted by step> 2000 break\n",
    "        total_reward = 0\n",
    "        epsilon = min_epsilon + (1.0 - min_epsilon)*np.exp(-decay_rate*ep)\n",
    "    # --> start episode\n",
    "        state = env.reset()\n",
    "        rews = []\n",
    "        for step in range(max_steps): # path = one episode\n",
    "            # generate the steps in each episode \n",
    "            # explore/exploit and get action using DQN\n",
    "            if random.random()<= epsilon:\n",
    "                action = np.random.randint(2, size=1)\n",
    "            else:\n",
    "                var_state = Variable(torch.unsqueeze(FloatTensor(state),0))# here change the (4,) to (1,4) in variable \n",
    "                DQN.model.eval()\n",
    "                Qs_actions = DQN.model.forward(var_state) # shape of (1, 2) variable\n",
    "                DQN.model.train()\n",
    "                cuda_tensor_action = torch.max(Qs_actions,1)[1].data\n",
    "                action = cuda_tensor_action.cpu().numpy()\n",
    "\n",
    "            new_state, reward, done, _ = env.step(int(action))\n",
    "            rews.append(reward)\n",
    "            replay.push((state, action, new_state, reward, done))\n",
    "            steps += 1\n",
    "        # perform action and record new_state, action, reward\n",
    "        # populate Replay experience buffer \n",
    "            if done:  break\n",
    "            else: state = new_state \n",
    "        # <-- end episode\n",
    "        path={'reward':np.array(rews)}\n",
    "        paths.append(path)\n",
    "        if steps > 2000: break\n",
    "    \n",
    "    batch_Q_behavior, batch_Q_target = replay.generate_minibatch(DQN, targetDQN, batch_size) #outputs and targets\n",
    "    DQN.learn(batch_Q_behavior, batch_Q_target) \n",
    "    targetDQN.model.load_state_dict(DQN.model.state_dict())\n",
    " \n",
    "    avg_reward = avg_reward * 0.95 + 0.05 * path['reward'].sum()\n",
    "    total_steps += steps\n",
    "    avg_rewards.append(avg_reward)\n",
    "    step_list_DQN.append(total_steps)\n",
    "    if ep % logging_interval == 0: print('Average reward: {}'.format(avg_reward)) \n",
    "print('finished training')\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average reward')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_rewards)\n",
    "plt.title('Training reward for <env> over multiple runs ')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 DQN post possing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "out = numpy_ewma_vectorized_v2(np.array(running_rewards_ddpg),20)\n",
    "plt.plot(step_list_ddpg, out) # or plt.plot(step_list_DQN, out)\n",
    "plt.title('Training reward over multiple runs')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.legend(['DDPG', 'REINFORCE']) #or plt.legend(['DQN', 'REINFORCE'])\n",
    "plt.plot(step_list_reinforce, avg_rewards)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
